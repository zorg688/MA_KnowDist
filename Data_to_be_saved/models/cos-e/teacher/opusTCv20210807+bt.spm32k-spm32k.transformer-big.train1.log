[2022-02-16 11:53:41] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-16 11:53:41] [marian] Running on r16g08.bullx as process 92035 with command line:
[2022-02-16 11:53:41] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10622088/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-02-16 11:53:41] [config] after: 0e
[2022-02-16 11:53:41] [config] after-batches: 0
[2022-02-16 11:53:41] [config] after-epochs: 0
[2022-02-16 11:53:41] [config] all-caps-every: 0
[2022-02-16 11:53:41] [config] allow-unk: true
[2022-02-16 11:53:41] [config] authors: false
[2022-02-16 11:53:41] [config] beam-size: 6
[2022-02-16 11:53:41] [config] bert-class-symbol: "[CLS]"
[2022-02-16 11:53:41] [config] bert-mask-symbol: "[MASK]"
[2022-02-16 11:53:41] [config] bert-masking-fraction: 0.15
[2022-02-16 11:53:41] [config] bert-sep-symbol: "[SEP]"
[2022-02-16 11:53:41] [config] bert-train-type-embeddings: true
[2022-02-16 11:53:41] [config] bert-type-vocab-size: 2
[2022-02-16 11:53:41] [config] build-info: ""
[2022-02-16 11:53:41] [config] check-gradient-nan: false
[2022-02-16 11:53:41] [config] check-nan: false
[2022-02-16 11:53:41] [config] cite: false
[2022-02-16 11:53:41] [config] clip-norm: 0
[2022-02-16 11:53:41] [config] cost-scaling:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] cost-type: ce-mean-words
[2022-02-16 11:53:41] [config] cpu-threads: 0
[2022-02-16 11:53:41] [config] data-weighting: ""
[2022-02-16 11:53:41] [config] data-weighting-type: sentence
[2022-02-16 11:53:41] [config] dec-cell: gru
[2022-02-16 11:53:41] [config] dec-cell-base-depth: 2
[2022-02-16 11:53:41] [config] dec-cell-high-depth: 1
[2022-02-16 11:53:41] [config] dec-depth: 6
[2022-02-16 11:53:41] [config] devices:
[2022-02-16 11:53:41] [config]   - 0
[2022-02-16 11:53:41] [config]   - 1
[2022-02-16 11:53:41] [config] dim-emb: 1024
[2022-02-16 11:53:41] [config] dim-rnn: 1024
[2022-02-16 11:53:41] [config] dim-vocabs:
[2022-02-16 11:53:41] [config]   - 0
[2022-02-16 11:53:41] [config]   - 0
[2022-02-16 11:53:41] [config] disp-first: 0
[2022-02-16 11:53:41] [config] disp-freq: 10000
[2022-02-16 11:53:41] [config] disp-label-counts: true
[2022-02-16 11:53:41] [config] dropout-rnn: 0
[2022-02-16 11:53:41] [config] dropout-src: 0
[2022-02-16 11:53:41] [config] dropout-trg: 0
[2022-02-16 11:53:41] [config] dump-config: ""
[2022-02-16 11:53:41] [config] dynamic-gradient-scaling:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] early-stopping: 10
[2022-02-16 11:53:41] [config] early-stopping-on: first
[2022-02-16 11:53:41] [config] embedding-fix-src: false
[2022-02-16 11:53:41] [config] embedding-fix-trg: false
[2022-02-16 11:53:41] [config] embedding-normalization: false
[2022-02-16 11:53:41] [config] embedding-vectors:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] enc-cell: gru
[2022-02-16 11:53:41] [config] enc-cell-depth: 1
[2022-02-16 11:53:41] [config] enc-depth: 6
[2022-02-16 11:53:41] [config] enc-type: bidirectional
[2022-02-16 11:53:41] [config] english-title-case-every: 0
[2022-02-16 11:53:41] [config] exponential-smoothing: 0.0001
[2022-02-16 11:53:41] [config] factor-weight: 1
[2022-02-16 11:53:41] [config] factors-combine: sum
[2022-02-16 11:53:41] [config] factors-dim-emb: 0
[2022-02-16 11:53:41] [config] gradient-checkpointing: false
[2022-02-16 11:53:41] [config] gradient-norm-average-window: 100
[2022-02-16 11:53:41] [config] guided-alignment: none
[2022-02-16 11:53:41] [config] guided-alignment-cost: mse
[2022-02-16 11:53:41] [config] guided-alignment-weight: 0.1
[2022-02-16 11:53:41] [config] ignore-model-config: false
[2022-02-16 11:53:41] [config] input-types:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] interpolate-env-vars: false
[2022-02-16 11:53:41] [config] keep-best: true
[2022-02-16 11:53:41] [config] label-smoothing: 0.1
[2022-02-16 11:53:41] [config] layer-normalization: false
[2022-02-16 11:53:41] [config] learn-rate: 0.0002
[2022-02-16 11:53:41] [config] lemma-dependency: ""
[2022-02-16 11:53:41] [config] lemma-dim-emb: 0
[2022-02-16 11:53:41] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-02-16 11:53:41] [config] log-level: info
[2022-02-16 11:53:41] [config] log-time-zone: ""
[2022-02-16 11:53:41] [config] logical-epoch:
[2022-02-16 11:53:41] [config]   - 1e
[2022-02-16 11:53:41] [config]   - 0
[2022-02-16 11:53:41] [config] lr-decay: 0
[2022-02-16 11:53:41] [config] lr-decay-freq: 50000
[2022-02-16 11:53:41] [config] lr-decay-inv-sqrt:
[2022-02-16 11:53:41] [config]   - 8000
[2022-02-16 11:53:41] [config] lr-decay-repeat-warmup: false
[2022-02-16 11:53:41] [config] lr-decay-reset-optimizer: false
[2022-02-16 11:53:41] [config] lr-decay-start:
[2022-02-16 11:53:41] [config]   - 10
[2022-02-16 11:53:41] [config]   - 1
[2022-02-16 11:53:41] [config] lr-decay-strategy: epoch+stalled
[2022-02-16 11:53:41] [config] lr-report: false
[2022-02-16 11:53:41] [config] lr-warmup: 8000
[2022-02-16 11:53:41] [config] lr-warmup-at-reload: false
[2022-02-16 11:53:41] [config] lr-warmup-cycle: false
[2022-02-16 11:53:41] [config] lr-warmup-start-rate: 0
[2022-02-16 11:53:41] [config] max-length: 100
[2022-02-16 11:53:41] [config] max-length-crop: false
[2022-02-16 11:53:41] [config] max-length-factor: 3
[2022-02-16 11:53:41] [config] maxi-batch: 1000
[2022-02-16 11:53:41] [config] maxi-batch-sort: trg
[2022-02-16 11:53:41] [config] mini-batch: 1000
[2022-02-16 11:53:41] [config] mini-batch-fit: true
[2022-02-16 11:53:41] [config] mini-batch-fit-step: 10
[2022-02-16 11:53:41] [config] mini-batch-round-up: true
[2022-02-16 11:53:41] [config] mini-batch-track-lr: false
[2022-02-16 11:53:41] [config] mini-batch-warmup: 0
[2022-02-16 11:53:41] [config] mini-batch-words: 0
[2022-02-16 11:53:41] [config] mini-batch-words-ref: 0
[2022-02-16 11:53:41] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-16 11:53:41] [config] multi-loss-type: sum
[2022-02-16 11:53:41] [config] n-best: false
[2022-02-16 11:53:41] [config] no-nccl: false
[2022-02-16 11:53:41] [config] no-reload: false
[2022-02-16 11:53:41] [config] no-restore-corpus: false
[2022-02-16 11:53:41] [config] normalize: 1
[2022-02-16 11:53:41] [config] normalize-gradient: false
[2022-02-16 11:53:41] [config] num-devices: 0
[2022-02-16 11:53:41] [config] optimizer: adam
[2022-02-16 11:53:41] [config] optimizer-delay: 2
[2022-02-16 11:53:41] [config] optimizer-params:
[2022-02-16 11:53:41] [config]   - 0.9
[2022-02-16 11:53:41] [config]   - 0.998
[2022-02-16 11:53:41] [config]   - 1e-09
[2022-02-16 11:53:41] [config] output-omit-bias: false
[2022-02-16 11:53:41] [config] overwrite: true
[2022-02-16 11:53:41] [config] precision:
[2022-02-16 11:53:41] [config]   - float32
[2022-02-16 11:53:41] [config]   - float32
[2022-02-16 11:53:41] [config] pretrained-model: ""
[2022-02-16 11:53:41] [config] quantize-biases: false
[2022-02-16 11:53:41] [config] quantize-bits: 0
[2022-02-16 11:53:41] [config] quantize-log-based: false
[2022-02-16 11:53:41] [config] quantize-optimization-steps: 0
[2022-02-16 11:53:41] [config] quiet: false
[2022-02-16 11:53:41] [config] quiet-translation: false
[2022-02-16 11:53:41] [config] relative-paths: false
[2022-02-16 11:53:41] [config] right-left: false
[2022-02-16 11:53:41] [config] save-freq: 10000
[2022-02-16 11:53:41] [config] seed: 1111
[2022-02-16 11:53:41] [config] sentencepiece-alphas:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] sentencepiece-max-lines: 2000000
[2022-02-16 11:53:41] [config] sentencepiece-options: ""
[2022-02-16 11:53:41] [config] sharding: local
[2022-02-16 11:53:41] [config] shuffle: batches
[2022-02-16 11:53:41] [config] shuffle-in-ram: false
[2022-02-16 11:53:41] [config] sigterm: save-and-exit
[2022-02-16 11:53:41] [config] skip: false
[2022-02-16 11:53:41] [config] sqlite: ""
[2022-02-16 11:53:41] [config] sqlite-drop: false
[2022-02-16 11:53:41] [config] sync-freq: 200u
[2022-02-16 11:53:41] [config] sync-sgd: true
[2022-02-16 11:53:41] [config] tempdir: /run/nvme/job_10622088/tmp
[2022-02-16 11:53:41] [config] tied-embeddings: false
[2022-02-16 11:53:41] [config] tied-embeddings-all: true
[2022-02-16 11:53:41] [config] tied-embeddings-src: false
[2022-02-16 11:53:41] [config] train-embedder-rank:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] train-sets:
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-02-16 11:53:41] [config] transformer-aan-activation: swish
[2022-02-16 11:53:41] [config] transformer-aan-depth: 2
[2022-02-16 11:53:41] [config] transformer-aan-nogate: false
[2022-02-16 11:53:41] [config] transformer-decoder-autoreg: self-attention
[2022-02-16 11:53:41] [config] transformer-depth-scaling: false
[2022-02-16 11:53:41] [config] transformer-dim-aan: 2048
[2022-02-16 11:53:41] [config] transformer-dim-ffn: 4096
[2022-02-16 11:53:41] [config] transformer-dropout: 0.1
[2022-02-16 11:53:41] [config] transformer-dropout-attention: 0
[2022-02-16 11:53:41] [config] transformer-dropout-ffn: 0
[2022-02-16 11:53:41] [config] transformer-ffn-activation: relu
[2022-02-16 11:53:41] [config] transformer-ffn-depth: 2
[2022-02-16 11:53:41] [config] transformer-guided-alignment-layer: last
[2022-02-16 11:53:41] [config] transformer-heads: 16
[2022-02-16 11:53:41] [config] transformer-no-projection: false
[2022-02-16 11:53:41] [config] transformer-pool: false
[2022-02-16 11:53:41] [config] transformer-postprocess: dan
[2022-02-16 11:53:41] [config] transformer-postprocess-emb: d
[2022-02-16 11:53:41] [config] transformer-postprocess-top: ""
[2022-02-16 11:53:41] [config] transformer-preprocess: ""
[2022-02-16 11:53:41] [config] transformer-tied-layers:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] transformer-train-position-embeddings: false
[2022-02-16 11:53:41] [config] tsv: false
[2022-02-16 11:53:41] [config] tsv-fields: 0
[2022-02-16 11:53:41] [config] type: transformer
[2022-02-16 11:53:41] [config] ulr: false
[2022-02-16 11:53:41] [config] ulr-dim-emb: 0
[2022-02-16 11:53:41] [config] ulr-dropout: 0
[2022-02-16 11:53:41] [config] ulr-keys-vectors: ""
[2022-02-16 11:53:41] [config] ulr-query-vectors: ""
[2022-02-16 11:53:41] [config] ulr-softmax-temperature: 1
[2022-02-16 11:53:41] [config] ulr-trainable-transformation: false
[2022-02-16 11:53:41] [config] unlikelihood-loss: false
[2022-02-16 11:53:41] [config] valid-freq: 10000
[2022-02-16 11:53:41] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-02-16 11:53:41] [config] valid-max-length: 100
[2022-02-16 11:53:41] [config] valid-metrics:
[2022-02-16 11:53:41] [config]   - perplexity
[2022-02-16 11:53:41] [config] valid-mini-batch: 16
[2022-02-16 11:53:41] [config] valid-reset-stalled: false
[2022-02-16 11:53:41] [config] valid-script-args:
[2022-02-16 11:53:41] [config]   []
[2022-02-16 11:53:41] [config] valid-script-path: ""
[2022-02-16 11:53:41] [config] valid-sets:
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-02-16 11:53:41] [config] valid-translation-output: ""
[2022-02-16 11:53:41] [config] vocabs:
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-16 11:53:41] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-16 11:53:41] [config] word-penalty: 0
[2022-02-16 11:53:41] [config] word-scores: false
[2022-02-16 11:53:41] [config] workspace: 15000
[2022-02-16 11:53:41] [config] Model is being created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-16 11:53:42] Using synchronous SGD
[2022-02-16 11:53:42] [comm] Compiled without MPI support. Running as a single process on r16g08.bullx
[2022-02-16 11:53:42] Synced seed 1111
[2022-02-16 11:53:42] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-16 11:53:42] [data] Setting vocabulary size for input 0 to 54,728
[2022-02-16 11:53:42] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-16 11:53:42] [data] Setting vocabulary size for input 1 to 54,728
[2022-02-16 11:53:42] [batching] Collecting statistics for batch fitting with step size 10
[2022-02-16 11:53:44] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-16 11:53:45] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-16 11:53:46] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-16 11:53:46] [comm] Using global sharding
[2022-02-16 11:53:47] [comm] NCCLCommunicators constructed successfully
[2022-02-16 11:53:47] [training] Using 2 GPUs
[2022-02-16 11:53:47] [logits] Applying loss function for 1 factor(s)
[2022-02-16 11:53:47] [memory] Reserving 886 MB, device gpu0
[2022-02-16 11:53:49] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-02-16 11:53:49] [memory] Reserving 886 MB, device gpu0
[2022-02-16 11:54:12] [batching] Done. Typical MB size is 27,536 target words
[2022-02-16 11:54:13] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-16 11:54:13] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-16 11:54:13] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-16 11:54:13] [comm] Using global sharding
[2022-02-16 11:54:13] [comm] NCCLCommunicators constructed successfully
[2022-02-16 11:54:13] [training] Using 2 GPUs
[2022-02-16 11:54:13] Training started
[2022-02-16 11:54:35] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-02-16 11:54:35] [memory] Reserving 886 MB, device gpu0
[2022-02-16 11:54:35] [memory] Reserving 886 MB, device gpu1
[2022-02-16 11:54:36] [memory] Reserving 886 MB, device gpu0
[2022-02-16 11:54:36] [memory] Reserving 886 MB, device gpu1
[2022-02-16 11:54:38] Parameter type float32, optimization type float32, casting types false
[2022-02-16 11:54:38] Allocating memory for general optimizer shards
[2022-02-16 11:54:38] [memory] Reserving 443 MB, device gpu0
[2022-02-16 11:54:38] [memory] Reserving 443 MB, device gpu1
[2022-02-16 11:54:38] Allocating memory for Adam-specific shards
[2022-02-16 11:54:38] [memory] Reserving 886 MB, device gpu1
[2022-02-16 11:54:38] [memory] Reserving 886 MB, device gpu0
[2022-02-16 15:29:11] Ep. 1 : Up. 10000 : Sen. 9,150,096 : Cost 5.18340206 : Time 12898.76s : 15924.22 words/s : gNorm 0.6459
[2022-02-16 15:29:12] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-16 15:29:16] Saving Adam parameters
[2022-02-16 15:29:21] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-16 15:29:29] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-16 15:29:31] [valid] Ep. 1 : Up. 10000 : perplexity : 11.2135 : new best
[2022-02-16 19:03:07] Ep. 1 : Up. 20000 : Sen. 18,283,672 : Cost 2.95733881 : Time 12835.50s : 15994.47 words/s : gNorm 0.4779
[2022-02-16 19:03:07] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-16 19:03:10] Saving Adam parameters
[2022-02-16 19:03:14] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-16 19:03:27] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-16 19:03:29] [valid] Ep. 1 : Up. 20000 : perplexity : 7.14335 : new best
[2022-02-16 22:37:17] Ep. 1 : Up. 30000 : Sen. 27,417,332 : Cost 2.75791192 : Time 12849.98s : 15980.94 words/s : gNorm 0.4541
[2022-02-16 22:37:17] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-16 22:37:20] Saving Adam parameters
[2022-02-16 22:37:24] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-16 22:37:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-16 22:37:34] [valid] Ep. 1 : Up. 30000 : perplexity : 6.30101 : new best
[2022-02-17 01:57:54] Error: not all input files have the same number of lines
[2022-02-17 01:57:54] Error: Aborted from virtual marian::data::SentenceTuple marian::data::Corpus::next() in /users/tiedeman/projappl/marian-dev/src/data/corpus.cpp:138

[CALL STACK]
[0x967826]          marian::data::Corpus::  next  ()                   + 0x1556
[0x94df6d]          marian::data::CorpusIterator::  increment  ()      + 0x1d
[0x8642ad]          marian::data::BatchGenerator<marian::data::CorpusBase>::  fetchBatches  () + 0xc3d
[0x864efa]          marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1}::  operator()  () const + 0x1a
[0x865ba0]          std::_Function_handler<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> (),std::__future_base::_Task_setter<std::unique_ptr<std::__future_base::_Result<std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>,std::__future_base::_Result_base::_Deleter>,std::__future_base::_Task_state<marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>> ()>::_M_run()::{lambda()#1},std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr<marian::data::CorpusBatch>>>>>::  _M_invoke  (std::_Any_data const&) + 0x30
[0x7a3d6b]          std::__future_base::_State_baseV2::  _M_do_set  (std::function<std::unique_ptr<std::__future_base::_Result_base,std::__future_base::_Result_base::_Deleter> ()>*,  bool*) + 0x1b
[0x7fb6bb1cc20b]                                                       + 0x620b
[0x7ae3f3]          std::__future_base::_Task_state<marian::ThreadPool::enqueue<marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}>(std::result_of&&,(marian::data::BatchGenerator<marian::data::CorpusBase>::fetchBatchesAsync()::{lambda()#1}&&)...)::{lambda()#1},std::allocator<int>,std::deque<std::shared_ptr<marian::data::CorpusBatch>,std::allocator<std::shared_ptr>> ()>::  _M_run  () + 0xe3
[0x7a58f0]          std::thread::_State_impl<std::thread::_Invoker<std::tuple<marian::ThreadPool::reserve(unsigned long)::{lambda()#1}>>>::  _M_run  () + 0x130
[0x7fb6bb730d4f]                                                       + 0xc3d4f
[0x7fb6bb1cdea5]                                                       + 0x7ea5
[0x7fb6ab3acb0d]    clone                                              + 0x6d

[2022-02-20 10:06:39] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-20 10:06:39] [marian] Running on r16g03.bullx as process 137088 with command line:
[2022-02-20 10:06:39] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10680698/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-02-20 10:06:40] [config] after: 0e
[2022-02-20 10:06:40] [config] after-batches: 0
[2022-02-20 10:06:40] [config] after-epochs: 0
[2022-02-20 10:06:40] [config] all-caps-every: 0
[2022-02-20 10:06:40] [config] allow-unk: true
[2022-02-20 10:06:40] [config] authors: false
[2022-02-20 10:06:40] [config] beam-size: 6
[2022-02-20 10:06:40] [config] bert-class-symbol: "[CLS]"
[2022-02-20 10:06:40] [config] bert-mask-symbol: "[MASK]"
[2022-02-20 10:06:40] [config] bert-masking-fraction: 0.15
[2022-02-20 10:06:40] [config] bert-sep-symbol: "[SEP]"
[2022-02-20 10:06:40] [config] bert-train-type-embeddings: true
[2022-02-20 10:06:40] [config] bert-type-vocab-size: 2
[2022-02-20 10:06:40] [config] build-info: ""
[2022-02-20 10:06:40] [config] check-gradient-nan: false
[2022-02-20 10:06:40] [config] check-nan: false
[2022-02-20 10:06:40] [config] cite: false
[2022-02-20 10:06:40] [config] clip-norm: 0
[2022-02-20 10:06:40] [config] cost-scaling:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] cost-type: ce-mean-words
[2022-02-20 10:06:40] [config] cpu-threads: 0
[2022-02-20 10:06:40] [config] data-weighting: ""
[2022-02-20 10:06:40] [config] data-weighting-type: sentence
[2022-02-20 10:06:40] [config] dec-cell: gru
[2022-02-20 10:06:40] [config] dec-cell-base-depth: 2
[2022-02-20 10:06:40] [config] dec-cell-high-depth: 1
[2022-02-20 10:06:40] [config] dec-depth: 6
[2022-02-20 10:06:40] [config] devices:
[2022-02-20 10:06:40] [config]   - 0
[2022-02-20 10:06:40] [config]   - 1
[2022-02-20 10:06:40] [config] dim-emb: 1024
[2022-02-20 10:06:40] [config] dim-rnn: 1024
[2022-02-20 10:06:40] [config] dim-vocabs:
[2022-02-20 10:06:40] [config]   - 54728
[2022-02-20 10:06:40] [config]   - 54728
[2022-02-20 10:06:40] [config] disp-first: 0
[2022-02-20 10:06:40] [config] disp-freq: 10000
[2022-02-20 10:06:40] [config] disp-label-counts: true
[2022-02-20 10:06:40] [config] dropout-rnn: 0
[2022-02-20 10:06:40] [config] dropout-src: 0
[2022-02-20 10:06:40] [config] dropout-trg: 0
[2022-02-20 10:06:40] [config] dump-config: ""
[2022-02-20 10:06:40] [config] dynamic-gradient-scaling:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] early-stopping: 10
[2022-02-20 10:06:40] [config] early-stopping-on: first
[2022-02-20 10:06:40] [config] embedding-fix-src: false
[2022-02-20 10:06:40] [config] embedding-fix-trg: false
[2022-02-20 10:06:40] [config] embedding-normalization: false
[2022-02-20 10:06:40] [config] embedding-vectors:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] enc-cell: gru
[2022-02-20 10:06:40] [config] enc-cell-depth: 1
[2022-02-20 10:06:40] [config] enc-depth: 6
[2022-02-20 10:06:40] [config] enc-type: bidirectional
[2022-02-20 10:06:40] [config] english-title-case-every: 0
[2022-02-20 10:06:40] [config] exponential-smoothing: 0.0001
[2022-02-20 10:06:40] [config] factor-weight: 1
[2022-02-20 10:06:40] [config] factors-combine: sum
[2022-02-20 10:06:40] [config] factors-dim-emb: 0
[2022-02-20 10:06:40] [config] gradient-checkpointing: false
[2022-02-20 10:06:40] [config] gradient-norm-average-window: 100
[2022-02-20 10:06:40] [config] guided-alignment: none
[2022-02-20 10:06:40] [config] guided-alignment-cost: mse
[2022-02-20 10:06:40] [config] guided-alignment-weight: 0.1
[2022-02-20 10:06:40] [config] ignore-model-config: false
[2022-02-20 10:06:40] [config] input-types:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] interpolate-env-vars: false
[2022-02-20 10:06:40] [config] keep-best: true
[2022-02-20 10:06:40] [config] label-smoothing: 0.1
[2022-02-20 10:06:40] [config] layer-normalization: false
[2022-02-20 10:06:40] [config] learn-rate: 0.0002
[2022-02-20 10:06:40] [config] lemma-dependency: ""
[2022-02-20 10:06:40] [config] lemma-dim-emb: 0
[2022-02-20 10:06:40] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-02-20 10:06:40] [config] log-level: info
[2022-02-20 10:06:40] [config] log-time-zone: ""
[2022-02-20 10:06:40] [config] logical-epoch:
[2022-02-20 10:06:40] [config]   - 1e
[2022-02-20 10:06:40] [config]   - 0
[2022-02-20 10:06:40] [config] lr-decay: 0
[2022-02-20 10:06:40] [config] lr-decay-freq: 50000
[2022-02-20 10:06:40] [config] lr-decay-inv-sqrt:
[2022-02-20 10:06:40] [config]   - 8000
[2022-02-20 10:06:40] [config] lr-decay-repeat-warmup: false
[2022-02-20 10:06:40] [config] lr-decay-reset-optimizer: false
[2022-02-20 10:06:40] [config] lr-decay-start:
[2022-02-20 10:06:40] [config]   - 10
[2022-02-20 10:06:40] [config]   - 1
[2022-02-20 10:06:40] [config] lr-decay-strategy: epoch+stalled
[2022-02-20 10:06:40] [config] lr-report: false
[2022-02-20 10:06:40] [config] lr-warmup: 8000
[2022-02-20 10:06:40] [config] lr-warmup-at-reload: false
[2022-02-20 10:06:40] [config] lr-warmup-cycle: false
[2022-02-20 10:06:40] [config] lr-warmup-start-rate: 0
[2022-02-20 10:06:40] [config] max-length: 100
[2022-02-20 10:06:40] [config] max-length-crop: false
[2022-02-20 10:06:40] [config] max-length-factor: 3
[2022-02-20 10:06:40] [config] maxi-batch: 1000
[2022-02-20 10:06:40] [config] maxi-batch-sort: trg
[2022-02-20 10:06:40] [config] mini-batch: 1000
[2022-02-20 10:06:40] [config] mini-batch-fit: true
[2022-02-20 10:06:40] [config] mini-batch-fit-step: 10
[2022-02-20 10:06:40] [config] mini-batch-round-up: true
[2022-02-20 10:06:40] [config] mini-batch-track-lr: false
[2022-02-20 10:06:40] [config] mini-batch-warmup: 0
[2022-02-20 10:06:40] [config] mini-batch-words: 0
[2022-02-20 10:06:40] [config] mini-batch-words-ref: 0
[2022-02-20 10:06:40] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 10:06:40] [config] multi-loss-type: sum
[2022-02-20 10:06:40] [config] n-best: false
[2022-02-20 10:06:40] [config] no-nccl: false
[2022-02-20 10:06:40] [config] no-reload: false
[2022-02-20 10:06:40] [config] no-restore-corpus: true
[2022-02-20 10:06:40] [config] normalize: 1
[2022-02-20 10:06:40] [config] normalize-gradient: false
[2022-02-20 10:06:40] [config] num-devices: 0
[2022-02-20 10:06:40] [config] optimizer: adam
[2022-02-20 10:06:40] [config] optimizer-delay: 2
[2022-02-20 10:06:40] [config] optimizer-params:
[2022-02-20 10:06:40] [config]   - 0.9
[2022-02-20 10:06:40] [config]   - 0.998
[2022-02-20 10:06:40] [config]   - 1e-09
[2022-02-20 10:06:40] [config] output-omit-bias: false
[2022-02-20 10:06:40] [config] overwrite: true
[2022-02-20 10:06:40] [config] precision:
[2022-02-20 10:06:40] [config]   - float32
[2022-02-20 10:06:40] [config]   - float32
[2022-02-20 10:06:40] [config] pretrained-model: ""
[2022-02-20 10:06:40] [config] quantize-biases: false
[2022-02-20 10:06:40] [config] quantize-bits: 0
[2022-02-20 10:06:40] [config] quantize-log-based: false
[2022-02-20 10:06:40] [config] quantize-optimization-steps: 0
[2022-02-20 10:06:40] [config] quiet: false
[2022-02-20 10:06:40] [config] quiet-translation: false
[2022-02-20 10:06:40] [config] relative-paths: false
[2022-02-20 10:06:40] [config] right-left: false
[2022-02-20 10:06:40] [config] save-freq: 10000
[2022-02-20 10:06:40] [config] seed: 1111
[2022-02-20 10:06:40] [config] sentencepiece-alphas:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] sentencepiece-max-lines: 2000000
[2022-02-20 10:06:40] [config] sentencepiece-options: ""
[2022-02-20 10:06:40] [config] sharding: local
[2022-02-20 10:06:40] [config] shuffle: batches
[2022-02-20 10:06:40] [config] shuffle-in-ram: false
[2022-02-20 10:06:40] [config] sigterm: save-and-exit
[2022-02-20 10:06:40] [config] skip: false
[2022-02-20 10:06:40] [config] sqlite: ""
[2022-02-20 10:06:40] [config] sqlite-drop: false
[2022-02-20 10:06:40] [config] sync-freq: 200u
[2022-02-20 10:06:40] [config] sync-sgd: true
[2022-02-20 10:06:40] [config] tempdir: /run/nvme/job_10680698/tmp
[2022-02-20 10:06:40] [config] tied-embeddings: false
[2022-02-20 10:06:40] [config] tied-embeddings-all: true
[2022-02-20 10:06:40] [config] tied-embeddings-src: false
[2022-02-20 10:06:40] [config] train-embedder-rank:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] train-sets:
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-02-20 10:06:40] [config] transformer-aan-activation: swish
[2022-02-20 10:06:40] [config] transformer-aan-depth: 2
[2022-02-20 10:06:40] [config] transformer-aan-nogate: false
[2022-02-20 10:06:40] [config] transformer-decoder-autoreg: self-attention
[2022-02-20 10:06:40] [config] transformer-depth-scaling: false
[2022-02-20 10:06:40] [config] transformer-dim-aan: 2048
[2022-02-20 10:06:40] [config] transformer-dim-ffn: 4096
[2022-02-20 10:06:40] [config] transformer-dropout: 0.1
[2022-02-20 10:06:40] [config] transformer-dropout-attention: 0
[2022-02-20 10:06:40] [config] transformer-dropout-ffn: 0
[2022-02-20 10:06:40] [config] transformer-ffn-activation: relu
[2022-02-20 10:06:40] [config] transformer-ffn-depth: 2
[2022-02-20 10:06:40] [config] transformer-guided-alignment-layer: last
[2022-02-20 10:06:40] [config] transformer-heads: 16
[2022-02-20 10:06:40] [config] transformer-no-projection: false
[2022-02-20 10:06:40] [config] transformer-pool: false
[2022-02-20 10:06:40] [config] transformer-postprocess: dan
[2022-02-20 10:06:40] [config] transformer-postprocess-emb: d
[2022-02-20 10:06:40] [config] transformer-postprocess-top: ""
[2022-02-20 10:06:40] [config] transformer-preprocess: ""
[2022-02-20 10:06:40] [config] transformer-tied-layers:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] transformer-train-position-embeddings: false
[2022-02-20 10:06:40] [config] tsv: false
[2022-02-20 10:06:40] [config] tsv-fields: 0
[2022-02-20 10:06:40] [config] type: transformer
[2022-02-20 10:06:40] [config] ulr: false
[2022-02-20 10:06:40] [config] ulr-dim-emb: 0
[2022-02-20 10:06:40] [config] ulr-dropout: 0
[2022-02-20 10:06:40] [config] ulr-keys-vectors: ""
[2022-02-20 10:06:40] [config] ulr-query-vectors: ""
[2022-02-20 10:06:40] [config] ulr-softmax-temperature: 1
[2022-02-20 10:06:40] [config] ulr-trainable-transformation: false
[2022-02-20 10:06:40] [config] unlikelihood-loss: false
[2022-02-20 10:06:40] [config] valid-freq: 10000
[2022-02-20 10:06:40] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-02-20 10:06:40] [config] valid-max-length: 100
[2022-02-20 10:06:40] [config] valid-metrics:
[2022-02-20 10:06:40] [config]   - perplexity
[2022-02-20 10:06:40] [config] valid-mini-batch: 16
[2022-02-20 10:06:40] [config] valid-reset-stalled: false
[2022-02-20 10:06:40] [config] valid-script-args:
[2022-02-20 10:06:40] [config]   []
[2022-02-20 10:06:40] [config] valid-script-path: ""
[2022-02-20 10:06:40] [config] valid-sets:
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-02-20 10:06:40] [config] valid-translation-output: ""
[2022-02-20 10:06:40] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-20 10:06:40] [config] vocabs:
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-20 10:06:40] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-20 10:06:40] [config] word-penalty: 0
[2022-02-20 10:06:40] [config] word-scores: false
[2022-02-20 10:06:40] [config] workspace: 15000
[2022-02-20 10:06:40] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-20 10:06:40] Using synchronous SGD
[2022-02-20 10:06:40] [comm] Compiled without MPI support. Running as a single process on r16g03.bullx
[2022-02-20 10:06:40] Synced seed 1111
[2022-02-20 10:06:41] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-20 10:06:41] [data] Setting vocabulary size for input 0 to 54,728
[2022-02-20 10:06:41] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-20 10:06:41] [data] Setting vocabulary size for input 1 to 54,728
[2022-02-20 10:06:41] [batching] Collecting statistics for batch fitting with step size 10
[2022-02-20 10:06:42] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-20 10:06:44] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-20 10:06:44] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-20 10:06:44] [comm] Using global sharding
[2022-02-20 10:06:44] [comm] NCCLCommunicators constructed successfully
[2022-02-20 10:06:44] [training] Using 2 GPUs
[2022-02-20 10:06:44] [logits] Applying loss function for 1 factor(s)
[2022-02-20 10:06:44] [memory] Reserving 886 MB, device gpu0
[2022-02-20 10:06:47] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-02-20 10:06:47] [memory] Reserving 886 MB, device gpu0
[2022-02-20 10:07:10] [batching] Done. Typical MB size is 27,536 target words
[2022-02-20 10:07:10] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-20 10:07:10] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-20 10:07:10] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-20 10:07:10] [comm] Using global sharding
[2022-02-20 10:07:11] [comm] NCCLCommunicators constructed successfully
[2022-02-20 10:07:11] [training] Using 2 GPUs
[2022-02-20 10:07:11] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 10:07:13] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 10:07:21] Allocating memory for general optimizer shards
[2022-02-20 10:07:21] [memory] Reserving 443 MB, device gpu0
[2022-02-20 10:07:21] [memory] Reserving 443 MB, device gpu1
[2022-02-20 10:07:21] Loading Adam parameters
[2022-02-20 10:07:22] [memory] Reserving 886 MB, device gpu0
[2022-02-20 10:07:22] [memory] Reserving 886 MB, device gpu1
[2022-02-20 10:07:22] [memory] Reserving 886 MB, device gpu0
[2022-02-20 10:07:22] [memory] Reserving 886 MB, device gpu1
[2022-02-20 10:07:23] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-20 10:07:23] Training started
[2022-02-20 10:07:46] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-02-20 10:07:46] [memory] Reserving 886 MB, device gpu0
[2022-02-20 10:07:46] [memory] Reserving 886 MB, device gpu1
[2022-02-20 10:07:48] Parameter type float32, optimization type float32, casting types false
[2022-02-20 13:40:56] Ep. 1 : Up. 40000 : Sen. 9,157,155 : Cost 2.67727113 : Time 12826.26s : 16012.88 words/s : gNorm 0.4954
[2022-02-20 13:40:56] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 13:41:00] Saving Adam parameters
[2022-02-20 13:41:04] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-20 13:41:12] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-20 13:41:14] [valid] Ep. 1 : Up. 40000 : perplexity : 5.88046 : new best
[2022-02-20 17:14:10] Ep. 1 : Up. 50000 : Sen. 18,299,011 : Cost 2.62834167 : Time 12793.21s : 16069.01 words/s : gNorm 0.4513
[2022-02-20 17:14:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 17:14:13] Saving Adam parameters
[2022-02-20 17:14:17] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-20 17:14:25] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-20 17:14:27] [valid] Ep. 1 : Up. 50000 : perplexity : 5.64276 : new best
[2022-02-20 20:47:08] Ep. 1 : Up. 60000 : Sen. 27,429,933 : Cost 2.59588647 : Time 12777.97s : 16076.71 words/s : gNorm 0.4247
[2022-02-20 20:47:08] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-20 20:47:11] Saving Adam parameters
[2022-02-20 20:47:14] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-20 20:47:22] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-20 20:47:25] [valid] Ep. 1 : Up. 60000 : perplexity : 5.4562 : new best
[2022-02-21 00:20:02] Ep. 1 : Up. 70000 : Sen. 36,599,477 : Cost 2.57223988 : Time 12773.73s : 16087.40 words/s : gNorm 0.4451
[2022-02-21 00:20:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 00:20:08] Saving Adam parameters
[2022-02-21 00:20:11] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 00:20:19] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 00:20:21] [valid] Ep. 1 : Up. 70000 : perplexity : 5.3212 : new best
[2022-02-21 03:52:59] Ep. 1 : Up. 80000 : Sen. 45,732,248 : Cost 2.55379748 : Time 12777.86s : 16066.19 words/s : gNorm 0.4312
[2022-02-21 03:53:00] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 03:53:03] Saving Adam parameters
[2022-02-21 03:53:06] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 03:53:14] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 03:53:16] [valid] Ep. 1 : Up. 80000 : perplexity : 5.21904 : new best
[2022-02-21 07:25:58] Ep. 1 : Up. 90000 : Sen. 54,887,710 : Cost 2.53807330 : Time 12778.95s : 16075.30 words/s : gNorm 0.4585
[2022-02-21 07:25:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 07:26:02] Saving Adam parameters
[2022-02-21 07:26:06] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 07:26:14] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 07:26:16] [valid] Ep. 1 : Up. 90000 : perplexity : 5.1202 : new best
[2022-02-21 10:59:15] Ep. 1 : Up. 100000 : Sen. 64,018,771 : Cost 2.52443218 : Time 12796.10s : 16052.92 words/s : gNorm 0.4724
[2022-02-21 10:59:15] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 10:59:22] Saving Adam parameters
[2022-02-21 10:59:28] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 10:59:38] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 10:59:41] [valid] Ep. 1 : Up. 100000 : perplexity : 5.04658 : new best
[2022-02-21 14:32:26] Ep. 1 : Up. 110000 : Sen. 73,175,796 : Cost 2.51392150 : Time 12791.57s : 16068.27 words/s : gNorm 0.4427
[2022-02-21 14:32:26] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 14:32:30] Saving Adam parameters
[2022-02-21 14:32:33] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 14:32:41] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 14:32:43] [valid] Ep. 1 : Up. 110000 : perplexity : 4.98513 : new best
[2022-02-21 18:05:29] Ep. 1 : Up. 120000 : Sen. 82,321,838 : Cost 2.50408912 : Time 12782.34s : 16069.40 words/s : gNorm 0.4561
[2022-02-21 18:05:29] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 18:05:32] Saving Adam parameters
[2022-02-21 18:05:36] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 18:05:45] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 18:05:47] [valid] Ep. 1 : Up. 120000 : perplexity : 4.93071 : new best
[2022-02-21 21:38:32] Ep. 1 : Up. 130000 : Sen. 91,465,281 : Cost 2.49642134 : Time 12783.17s : 16069.72 words/s : gNorm 0.4893
[2022-02-21 21:38:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-21 21:38:35] Saving Adam parameters
[2022-02-21 21:38:39] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-21 21:38:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-21 21:38:49] [valid] Ep. 1 : Up. 130000 : perplexity : 4.88305 : new best
[2022-02-22 01:11:43] Ep. 1 : Up. 140000 : Sen. 100,615,039 : Cost 2.48841572 : Time 12791.06s : 16067.39 words/s : gNorm 0.4683
[2022-02-22 01:11:43] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 01:11:47] Saving Adam parameters
[2022-02-22 01:11:51] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 01:11:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 01:12:01] [valid] Ep. 1 : Up. 140000 : perplexity : 4.8438 : new best
[2022-02-22 04:44:43] Ep. 1 : Up. 150000 : Sen. 109,738,459 : Cost 2.48105812 : Time 12780.22s : 16077.16 words/s : gNorm 0.5078
[2022-02-22 04:44:43] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 04:44:47] Saving Adam parameters
[2022-02-22 04:44:50] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 04:44:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 04:45:01] [valid] Ep. 1 : Up. 150000 : perplexity : 4.80817 : new best
[2022-02-22 08:17:45] Ep. 1 : Up. 160000 : Sen. 118,905,778 : Cost 2.47632527 : Time 12781.98s : 16067.44 words/s : gNorm 0.4794
[2022-02-22 08:17:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 08:17:49] Saving Adam parameters
[2022-02-22 08:17:53] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 08:18:05] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 08:18:07] [valid] Ep. 1 : Up. 160000 : perplexity : 4.76898 : new best
[2022-02-22 11:51:10] Ep. 1 : Up. 170000 : Sen. 128,053,008 : Cost 2.47044086 : Time 12804.15s : 16048.54 words/s : gNorm 0.4760
[2022-02-22 11:51:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 11:51:13] Saving Adam parameters
[2022-02-22 11:51:16] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 11:51:24] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 11:51:26] [valid] Ep. 1 : Up. 170000 : perplexity : 4.74337 : new best
[2022-02-22 15:24:05] Ep. 1 : Up. 180000 : Sen. 137,193,522 : Cost 2.46490121 : Time 12774.84s : 16076.53 words/s : gNorm 0.4735
[2022-02-22 15:24:05] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 15:24:08] Saving Adam parameters
[2022-02-22 15:24:12] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 15:24:20] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 15:24:22] [valid] Ep. 1 : Up. 180000 : perplexity : 4.71023 : new best
[2022-02-22 18:57:17] Ep. 1 : Up. 190000 : Sen. 146,351,606 : Cost 2.46150231 : Time 12792.38s : 16056.63 words/s : gNorm 0.5173
[2022-02-22 18:57:17] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 18:57:20] Saving Adam parameters
[2022-02-22 18:57:24] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 18:57:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 18:57:34] [valid] Ep. 1 : Up. 190000 : perplexity : 4.68491 : new best
[2022-02-22 22:30:23] Ep. 1 : Up. 200000 : Sen. 155,474,105 : Cost 2.45630503 : Time 12786.23s : 16056.80 words/s : gNorm 0.4900
[2022-02-22 22:30:23] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-22 22:30:26] Saving Adam parameters
[2022-02-22 22:30:30] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-22 22:30:38] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-22 22:30:40] [valid] Ep. 1 : Up. 200000 : perplexity : 4.65924 : new best
[2022-02-23 02:03:40] Ep. 1 : Up. 210000 : Sen. 164,619,953 : Cost 2.45146060 : Time 12797.16s : 16056.92 words/s : gNorm 0.4709
[2022-02-23 02:03:41] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 02:03:44] Saving Adam parameters
[2022-02-23 02:03:47] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 02:03:55] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 02:03:58] [valid] Ep. 1 : Up. 210000 : perplexity : 4.64655 : new best
[2022-02-23 05:36:47] Ep. 1 : Up. 220000 : Sen. 173,759,503 : Cost 2.44826984 : Time 12786.85s : 16073.58 words/s : gNorm 0.5001
[2022-02-23 05:36:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 05:36:50] Saving Adam parameters
[2022-02-23 05:36:54] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 05:37:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 05:37:04] [valid] Ep. 1 : Up. 220000 : perplexity : 4.63159 : new best
[2022-02-23 09:09:34] Ep. 1 : Up. 230000 : Sen. 182,912,066 : Cost 2.44574761 : Time 12767.11s : 16088.10 words/s : gNorm 0.5135
[2022-02-23 09:09:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 09:09:38] Saving Adam parameters
[2022-02-23 09:09:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 09:09:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 09:09:52] [valid] Ep. 1 : Up. 230000 : perplexity : 4.61727 : new best
[2022-02-23 10:08:07] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-23 10:08:07] [marian] Running on r18g05.bullx as process 134101 with command line:
[2022-02-23 10:08:07] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10689020/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-02-23 10:08:09] [config] after: 0e
[2022-02-23 10:08:09] [config] after-batches: 0
[2022-02-23 10:08:09] [config] after-epochs: 0
[2022-02-23 10:08:09] [config] all-caps-every: 0
[2022-02-23 10:08:09] [config] allow-unk: true
[2022-02-23 10:08:09] [config] authors: false
[2022-02-23 10:08:09] [config] beam-size: 6
[2022-02-23 10:08:09] [config] bert-class-symbol: "[CLS]"
[2022-02-23 10:08:09] [config] bert-mask-symbol: "[MASK]"
[2022-02-23 10:08:09] [config] bert-masking-fraction: 0.15
[2022-02-23 10:08:09] [config] bert-sep-symbol: "[SEP]"
[2022-02-23 10:08:09] [config] bert-train-type-embeddings: true
[2022-02-23 10:08:09] [config] bert-type-vocab-size: 2
[2022-02-23 10:08:09] [config] build-info: ""
[2022-02-23 10:08:09] [config] check-gradient-nan: false
[2022-02-23 10:08:09] [config] check-nan: false
[2022-02-23 10:08:09] [config] cite: false
[2022-02-23 10:08:09] [config] clip-norm: 0
[2022-02-23 10:08:09] [config] cost-scaling:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] cost-type: ce-mean-words
[2022-02-23 10:08:09] [config] cpu-threads: 0
[2022-02-23 10:08:09] [config] data-weighting: ""
[2022-02-23 10:08:09] [config] data-weighting-type: sentence
[2022-02-23 10:08:09] [config] dec-cell: gru
[2022-02-23 10:08:09] [config] dec-cell-base-depth: 2
[2022-02-23 10:08:09] [config] dec-cell-high-depth: 1
[2022-02-23 10:08:09] [config] dec-depth: 6
[2022-02-23 10:08:09] [config] devices:
[2022-02-23 10:08:09] [config]   - 0
[2022-02-23 10:08:09] [config]   - 1
[2022-02-23 10:08:09] [config] dim-emb: 1024
[2022-02-23 10:08:09] [config] dim-rnn: 1024
[2022-02-23 10:08:09] [config] dim-vocabs:
[2022-02-23 10:08:09] [config]   - 54728
[2022-02-23 10:08:09] [config]   - 54728
[2022-02-23 10:08:09] [config] disp-first: 0
[2022-02-23 10:08:09] [config] disp-freq: 10000
[2022-02-23 10:08:09] [config] disp-label-counts: true
[2022-02-23 10:08:09] [config] dropout-rnn: 0
[2022-02-23 10:08:09] [config] dropout-src: 0
[2022-02-23 10:08:09] [config] dropout-trg: 0
[2022-02-23 10:08:09] [config] dump-config: ""
[2022-02-23 10:08:09] [config] dynamic-gradient-scaling:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] early-stopping: 10
[2022-02-23 10:08:09] [config] early-stopping-on: first
[2022-02-23 10:08:09] [config] embedding-fix-src: false
[2022-02-23 10:08:09] [config] embedding-fix-trg: false
[2022-02-23 10:08:09] [config] embedding-normalization: false
[2022-02-23 10:08:09] [config] embedding-vectors:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] enc-cell: gru
[2022-02-23 10:08:09] [config] enc-cell-depth: 1
[2022-02-23 10:08:09] [config] enc-depth: 6
[2022-02-23 10:08:09] [config] enc-type: bidirectional
[2022-02-23 10:08:09] [config] english-title-case-every: 0
[2022-02-23 10:08:09] [config] exponential-smoothing: 0.0001
[2022-02-23 10:08:09] [config] factor-weight: 1
[2022-02-23 10:08:09] [config] factors-combine: sum
[2022-02-23 10:08:09] [config] factors-dim-emb: 0
[2022-02-23 10:08:09] [config] gradient-checkpointing: false
[2022-02-23 10:08:09] [config] gradient-norm-average-window: 100
[2022-02-23 10:08:09] [config] guided-alignment: none
[2022-02-23 10:08:09] [config] guided-alignment-cost: mse
[2022-02-23 10:08:09] [config] guided-alignment-weight: 0.1
[2022-02-23 10:08:09] [config] ignore-model-config: false
[2022-02-23 10:08:09] [config] input-types:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] interpolate-env-vars: false
[2022-02-23 10:08:09] [config] keep-best: true
[2022-02-23 10:08:09] [config] label-smoothing: 0.1
[2022-02-23 10:08:09] [config] layer-normalization: false
[2022-02-23 10:08:09] [config] learn-rate: 0.0002
[2022-02-23 10:08:09] [config] lemma-dependency: ""
[2022-02-23 10:08:09] [config] lemma-dim-emb: 0
[2022-02-23 10:08:09] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-02-23 10:08:09] [config] log-level: info
[2022-02-23 10:08:09] [config] log-time-zone: ""
[2022-02-23 10:08:09] [config] logical-epoch:
[2022-02-23 10:08:09] [config]   - 1e
[2022-02-23 10:08:09] [config]   - 0
[2022-02-23 10:08:09] [config] lr-decay: 0
[2022-02-23 10:08:09] [config] lr-decay-freq: 50000
[2022-02-23 10:08:09] [config] lr-decay-inv-sqrt:
[2022-02-23 10:08:09] [config]   - 8000
[2022-02-23 10:08:09] [config] lr-decay-repeat-warmup: false
[2022-02-23 10:08:09] [config] lr-decay-reset-optimizer: false
[2022-02-23 10:08:09] [config] lr-decay-start:
[2022-02-23 10:08:09] [config]   - 10
[2022-02-23 10:08:09] [config]   - 1
[2022-02-23 10:08:09] [config] lr-decay-strategy: epoch+stalled
[2022-02-23 10:08:09] [config] lr-report: false
[2022-02-23 10:08:09] [config] lr-warmup: 8000
[2022-02-23 10:08:09] [config] lr-warmup-at-reload: false
[2022-02-23 10:08:09] [config] lr-warmup-cycle: false
[2022-02-23 10:08:09] [config] lr-warmup-start-rate: 0
[2022-02-23 10:08:09] [config] max-length: 100
[2022-02-23 10:08:09] [config] max-length-crop: false
[2022-02-23 10:08:09] [config] max-length-factor: 3
[2022-02-23 10:08:09] [config] maxi-batch: 1000
[2022-02-23 10:08:09] [config] maxi-batch-sort: trg
[2022-02-23 10:08:09] [config] mini-batch: 1000
[2022-02-23 10:08:09] [config] mini-batch-fit: true
[2022-02-23 10:08:09] [config] mini-batch-fit-step: 10
[2022-02-23 10:08:09] [config] mini-batch-round-up: true
[2022-02-23 10:08:09] [config] mini-batch-track-lr: false
[2022-02-23 10:08:09] [config] mini-batch-warmup: 0
[2022-02-23 10:08:09] [config] mini-batch-words: 0
[2022-02-23 10:08:09] [config] mini-batch-words-ref: 0
[2022-02-23 10:08:09] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 10:08:09] [config] multi-loss-type: sum
[2022-02-23 10:08:09] [config] n-best: false
[2022-02-23 10:08:09] [config] no-nccl: false
[2022-02-23 10:08:09] [config] no-reload: false
[2022-02-23 10:08:09] [config] no-restore-corpus: true
[2022-02-23 10:08:09] [config] normalize: 1
[2022-02-23 10:08:09] [config] normalize-gradient: false
[2022-02-23 10:08:09] [config] num-devices: 0
[2022-02-23 10:08:09] [config] optimizer: adam
[2022-02-23 10:08:09] [config] optimizer-delay: 2
[2022-02-23 10:08:09] [config] optimizer-params:
[2022-02-23 10:08:09] [config]   - 0.9
[2022-02-23 10:08:09] [config]   - 0.998
[2022-02-23 10:08:09] [config]   - 1e-09
[2022-02-23 10:08:09] [config] output-omit-bias: false
[2022-02-23 10:08:09] [config] overwrite: true
[2022-02-23 10:08:09] [config] precision:
[2022-02-23 10:08:09] [config]   - float32
[2022-02-23 10:08:09] [config]   - float32
[2022-02-23 10:08:09] [config] pretrained-model: ""
[2022-02-23 10:08:09] [config] quantize-biases: false
[2022-02-23 10:08:09] [config] quantize-bits: 0
[2022-02-23 10:08:09] [config] quantize-log-based: false
[2022-02-23 10:08:09] [config] quantize-optimization-steps: 0
[2022-02-23 10:08:09] [config] quiet: false
[2022-02-23 10:08:09] [config] quiet-translation: false
[2022-02-23 10:08:09] [config] relative-paths: false
[2022-02-23 10:08:09] [config] right-left: false
[2022-02-23 10:08:09] [config] save-freq: 10000
[2022-02-23 10:08:09] [config] seed: 1111
[2022-02-23 10:08:09] [config] sentencepiece-alphas:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] sentencepiece-max-lines: 2000000
[2022-02-23 10:08:09] [config] sentencepiece-options: ""
[2022-02-23 10:08:09] [config] sharding: local
[2022-02-23 10:08:09] [config] shuffle: batches
[2022-02-23 10:08:09] [config] shuffle-in-ram: false
[2022-02-23 10:08:09] [config] sigterm: save-and-exit
[2022-02-23 10:08:09] [config] skip: false
[2022-02-23 10:08:09] [config] sqlite: ""
[2022-02-23 10:08:09] [config] sqlite-drop: false
[2022-02-23 10:08:09] [config] sync-freq: 200u
[2022-02-23 10:08:09] [config] sync-sgd: true
[2022-02-23 10:08:09] [config] tempdir: /run/nvme/job_10689020/tmp
[2022-02-23 10:08:09] [config] tied-embeddings: false
[2022-02-23 10:08:09] [config] tied-embeddings-all: true
[2022-02-23 10:08:09] [config] tied-embeddings-src: false
[2022-02-23 10:08:09] [config] train-embedder-rank:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] train-sets:
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-02-23 10:08:09] [config] transformer-aan-activation: swish
[2022-02-23 10:08:09] [config] transformer-aan-depth: 2
[2022-02-23 10:08:09] [config] transformer-aan-nogate: false
[2022-02-23 10:08:09] [config] transformer-decoder-autoreg: self-attention
[2022-02-23 10:08:09] [config] transformer-depth-scaling: false
[2022-02-23 10:08:09] [config] transformer-dim-aan: 2048
[2022-02-23 10:08:09] [config] transformer-dim-ffn: 4096
[2022-02-23 10:08:09] [config] transformer-dropout: 0.1
[2022-02-23 10:08:09] [config] transformer-dropout-attention: 0
[2022-02-23 10:08:09] [config] transformer-dropout-ffn: 0
[2022-02-23 10:08:09] [config] transformer-ffn-activation: relu
[2022-02-23 10:08:09] [config] transformer-ffn-depth: 2
[2022-02-23 10:08:09] [config] transformer-guided-alignment-layer: last
[2022-02-23 10:08:09] [config] transformer-heads: 16
[2022-02-23 10:08:09] [config] transformer-no-projection: false
[2022-02-23 10:08:09] [config] transformer-pool: false
[2022-02-23 10:08:09] [config] transformer-postprocess: dan
[2022-02-23 10:08:09] [config] transformer-postprocess-emb: d
[2022-02-23 10:08:09] [config] transformer-postprocess-top: ""
[2022-02-23 10:08:09] [config] transformer-preprocess: ""
[2022-02-23 10:08:09] [config] transformer-tied-layers:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] transformer-train-position-embeddings: false
[2022-02-23 10:08:09] [config] tsv: false
[2022-02-23 10:08:09] [config] tsv-fields: 0
[2022-02-23 10:08:09] [config] type: transformer
[2022-02-23 10:08:09] [config] ulr: false
[2022-02-23 10:08:09] [config] ulr-dim-emb: 0
[2022-02-23 10:08:09] [config] ulr-dropout: 0
[2022-02-23 10:08:09] [config] ulr-keys-vectors: ""
[2022-02-23 10:08:09] [config] ulr-query-vectors: ""
[2022-02-23 10:08:09] [config] ulr-softmax-temperature: 1
[2022-02-23 10:08:09] [config] ulr-trainable-transformation: false
[2022-02-23 10:08:09] [config] unlikelihood-loss: false
[2022-02-23 10:08:09] [config] valid-freq: 10000
[2022-02-23 10:08:09] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-02-23 10:08:09] [config] valid-max-length: 100
[2022-02-23 10:08:09] [config] valid-metrics:
[2022-02-23 10:08:09] [config]   - perplexity
[2022-02-23 10:08:09] [config] valid-mini-batch: 16
[2022-02-23 10:08:09] [config] valid-reset-stalled: false
[2022-02-23 10:08:09] [config] valid-script-args:
[2022-02-23 10:08:09] [config]   []
[2022-02-23 10:08:09] [config] valid-script-path: ""
[2022-02-23 10:08:09] [config] valid-sets:
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-02-23 10:08:09] [config] valid-translation-output: ""
[2022-02-23 10:08:09] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-23 10:08:09] [config] vocabs:
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-23 10:08:09] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-23 10:08:09] [config] word-penalty: 0
[2022-02-23 10:08:09] [config] word-scores: false
[2022-02-23 10:08:09] [config] workspace: 15000
[2022-02-23 10:08:09] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-23 10:08:09] Using synchronous SGD
[2022-02-23 10:08:09] [comm] Compiled without MPI support. Running as a single process on r18g05.bullx
[2022-02-23 10:08:09] Synced seed 1111
[2022-02-23 10:08:09] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-23 10:08:09] [data] Setting vocabulary size for input 0 to 54,728
[2022-02-23 10:08:09] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-23 10:08:09] [data] Setting vocabulary size for input 1 to 54,728
[2022-02-23 10:08:09] [batching] Collecting statistics for batch fitting with step size 10
[2022-02-23 10:08:11] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-23 10:08:12] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-23 10:08:13] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-23 10:08:13] [comm] Using global sharding
[2022-02-23 10:08:14] [comm] NCCLCommunicators constructed successfully
[2022-02-23 10:08:14] [training] Using 2 GPUs
[2022-02-23 10:08:14] [logits] Applying loss function for 1 factor(s)
[2022-02-23 10:08:14] [memory] Reserving 886 MB, device gpu0
[2022-02-23 10:08:19] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-02-23 10:08:19] [memory] Reserving 886 MB, device gpu0
[2022-02-23 10:08:42] [batching] Done. Typical MB size is 27,536 target words
[2022-02-23 10:08:42] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-23 10:08:43] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-23 10:08:43] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-23 10:08:43] [comm] Using global sharding
[2022-02-23 10:08:44] [comm] NCCLCommunicators constructed successfully
[2022-02-23 10:08:44] [training] Using 2 GPUs
[2022-02-23 10:08:46] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 10:08:48] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 10:08:56] Allocating memory for general optimizer shards
[2022-02-23 10:08:56] [memory] Reserving 443 MB, device gpu0
[2022-02-23 10:08:57] [memory] Reserving 443 MB, device gpu1
[2022-02-23 10:08:57] Loading Adam parameters
[2022-02-23 10:08:57] [memory] Reserving 886 MB, device gpu0
[2022-02-23 10:08:57] [memory] Reserving 886 MB, device gpu1
[2022-02-23 10:08:58] [memory] Reserving 886 MB, device gpu0
[2022-02-23 10:08:58] [memory] Reserving 886 MB, device gpu1
[2022-02-23 10:08:59] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 10:08:59] Training started
[2022-02-23 10:09:21] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-02-23 10:09:21] [memory] Reserving 886 MB, device gpu0
[2022-02-23 10:09:22] [memory] Reserving 886 MB, device gpu1
[2022-02-23 10:09:24] Parameter type float32, optimization type float32, casting types false
[2022-02-23 13:42:30] Ep. 1 : Up. 240000 : Sen. 9,157,155 : Cost 2.43790269 : Time 12827.75s : 16011.03 words/s : gNorm 0.5393
[2022-02-23 13:42:30] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 13:42:34] Saving Adam parameters
[2022-02-23 13:42:37] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 13:42:45] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 13:42:48] [valid] Ep. 1 : Up. 240000 : perplexity : 4.59747 : new best
[2022-02-23 17:15:54] Ep. 1 : Up. 250000 : Sen. 18,299,011 : Cost 2.43324566 : Time 12803.87s : 16055.63 words/s : gNorm 0.5041
[2022-02-23 17:15:54] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 17:15:58] Saving Adam parameters
[2022-02-23 17:16:01] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 17:16:09] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 17:16:11] [valid] Ep. 1 : Up. 250000 : perplexity : 4.58658 : new best
[2022-02-23 20:51:49] Ep. 1 : Up. 260000 : Sen. 27,429,933 : Cost 2.42999029 : Time 12955.24s : 15856.73 words/s : gNorm 0.4698
[2022-02-23 20:54:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-23 20:54:13] Saving Adam parameters
[2022-02-23 20:54:17] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-23 20:54:25] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-23 20:54:27] [valid] Ep. 1 : Up. 260000 : perplexity : 4.57646 : new best
[2022-02-24 00:33:18] Ep. 1 : Up. 270000 : Sen. 36,599,477 : Cost 2.42741251 : Time 13148.30s : 15629.10 words/s : gNorm 0.4997
[2022-02-24 00:33:18] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 00:33:22] Saving Adam parameters
[2022-02-24 00:33:25] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 00:33:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 00:33:36] [valid] Ep. 1 : Up. 270000 : perplexity : 4.56304 : new best
[2022-02-24 04:06:28] Ep. 1 : Up. 280000 : Sen. 45,732,248 : Cost 2.42495751 : Time 12790.14s : 16050.77 words/s : gNorm 0.4891
[2022-02-24 04:06:28] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 04:06:32] Saving Adam parameters
[2022-02-24 04:06:35] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 04:06:43] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 04:06:46] [valid] Ep. 1 : Up. 280000 : perplexity : 4.54942 : new best
[2022-02-24 07:39:34] Ep. 1 : Up. 290000 : Sen. 54,887,710 : Cost 2.42206383 : Time 12786.02s : 16066.41 words/s : gNorm 0.5153
[2022-02-24 07:39:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 07:39:38] Saving Adam parameters
[2022-02-24 07:39:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 07:39:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 07:39:51] [valid] Ep. 1 : Up. 290000 : perplexity : 4.53227 : new best
[2022-02-24 11:13:02] Ep. 1 : Up. 300000 : Sen. 64,018,771 : Cost 2.41878748 : Time 12807.49s : 16038.66 words/s : gNorm 0.5382
[2022-02-24 11:13:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 11:13:09] Saving Adam parameters
[2022-02-24 11:13:16] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 11:13:26] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 11:13:28] [valid] Ep. 1 : Up. 300000 : perplexity : 4.51702 : new best
[2022-02-24 14:46:20] Ep. 1 : Up. 310000 : Sen. 73,175,796 : Cost 2.41700125 : Time 12798.07s : 16060.11 words/s : gNorm 0.4947
[2022-02-24 14:46:20] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 14:46:24] Saving Adam parameters
[2022-02-24 14:46:27] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 14:46:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 14:46:38] [valid] Ep. 1 : Up. 310000 : perplexity : 4.51465 : new best
[2022-02-24 18:22:34] Ep. 1 : Up. 320000 : Sen. 82,321,838 : Cost 2.41440296 : Time 12973.95s : 15832.08 words/s : gNorm 0.5093
[2022-02-24 18:22:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 18:22:38] Saving Adam parameters
[2022-02-24 18:22:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 18:22:50] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 18:22:52] [valid] Ep. 1 : Up. 320000 : perplexity : 4.50666 : new best
[2022-02-24 21:55:48] Ep. 1 : Up. 330000 : Sen. 91,465,281 : Cost 2.41297364 : Time 12793.81s : 16056.35 words/s : gNorm 0.5601
[2022-02-24 21:55:48] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-24 21:55:52] Saving Adam parameters
[2022-02-24 21:55:55] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-24 21:56:03] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-24 21:56:05] [valid] Ep. 1 : Up. 330000 : perplexity : 4.49415 : new best
[2022-02-25 01:28:57] Ep. 1 : Up. 340000 : Sen. 100,615,039 : Cost 2.41043067 : Time 12788.94s : 16070.05 words/s : gNorm 0.5200
[2022-02-25 01:28:57] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 01:29:01] Saving Adam parameters
[2022-02-25 01:29:04] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 01:29:12] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 01:29:14] [valid] Ep. 1 : Up. 340000 : perplexity : 4.48334 : new best
[2022-02-25 05:01:51] Ep. 1 : Up. 350000 : Sen. 109,738,459 : Cost 2.40791893 : Time 12774.23s : 16084.70 words/s : gNorm 0.5728
[2022-02-25 05:01:51] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 05:01:55] Saving Adam parameters
[2022-02-25 05:01:58] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 05:02:06] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 05:02:08] [valid] Ep. 1 : Up. 350000 : perplexity : 4.47466 : new best
[2022-02-25 08:34:52] Ep. 1 : Up. 360000 : Sen. 118,905,778 : Cost 2.40747881 : Time 12780.91s : 16068.79 words/s : gNorm 0.5327
[2022-02-25 08:34:52] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 08:34:56] Saving Adam parameters
[2022-02-25 08:34:59] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 08:35:08] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 08:35:10] [valid] Ep. 1 : Up. 360000 : perplexity : 4.46408 : new best
[2022-02-25 12:08:46] Ep. 1 : Up. 370000 : Sen. 128,053,008 : Cost 2.40534496 : Time 12833.88s : 16011.36 words/s : gNorm 0.5360
[2022-02-25 12:08:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 12:08:53] Saving Adam parameters
[2022-02-25 12:08:56] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 12:09:07] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 12:09:09] [valid] Ep. 1 : Up. 370000 : perplexity : 4.45695 : new best
[2022-02-25 15:41:55] Ep. 1 : Up. 380000 : Sen. 137,193,522 : Cost 2.40322995 : Time 12788.86s : 16058.90 words/s : gNorm 0.5203
[2022-02-25 15:41:56] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 15:41:59] Saving Adam parameters
[2022-02-25 15:42:02] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 15:42:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 15:42:12] [valid] Ep. 1 : Up. 380000 : perplexity : 4.44626 : new best
[2022-02-25 19:15:14] Ep. 1 : Up. 390000 : Sen. 146,351,606 : Cost 2.40294886 : Time 12798.49s : 16048.96 words/s : gNorm 0.5823
[2022-02-25 19:15:14] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 19:15:17] Saving Adam parameters
[2022-02-25 19:15:21] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 19:15:29] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 19:15:31] [valid] Ep. 1 : Up. 390000 : perplexity : 4.43716 : new best
[2022-02-25 22:48:16] Ep. 1 : Up. 400000 : Sen. 155,474,105 : Cost 2.40042710 : Time 12782.26s : 16061.79 words/s : gNorm 0.5422
[2022-02-25 22:48:16] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-25 22:48:20] Saving Adam parameters
[2022-02-25 22:48:23] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-25 22:48:31] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-25 22:48:33] [valid] Ep. 1 : Up. 400000 : perplexity : 4.42461 : new best
[2022-02-26 02:21:26] Ep. 1 : Up. 410000 : Sen. 164,619,953 : Cost 2.39828730 : Time 12789.77s : 16066.20 words/s : gNorm 0.5170
[2022-02-26 02:21:27] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 02:21:30] Saving Adam parameters
[2022-02-26 02:21:34] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 02:21:43] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 02:21:45] [valid] Ep. 1 : Up. 410000 : perplexity : 4.4228 : new best
[2022-02-26 05:54:34] Ep. 1 : Up. 420000 : Sen. 173,759,503 : Cost 2.39743114 : Time 12788.14s : 16071.96 words/s : gNorm 0.5546
[2022-02-26 05:54:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 05:54:38] Saving Adam parameters
[2022-02-26 05:54:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 05:54:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 05:54:52] [valid] Ep. 1 : Up. 420000 : perplexity : 4.41936 : new best
[2022-02-26 09:27:37] Ep. 1 : Up. 430000 : Sen. 182,912,066 : Cost 2.39713097 : Time 12782.86s : 16068.28 words/s : gNorm 0.5684
[2022-02-26 09:27:37] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 09:27:41] Saving Adam parameters
[2022-02-26 09:27:44] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 09:27:52] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 09:27:55] [valid] Ep. 1 : Up. 430000 : perplexity : 4.41301 : new best
[2022-02-26 10:08:31] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-26 10:08:31] [marian] Running on r18g05.bullx as process 134535 with command line:
[2022-02-26 10:08:31] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10746062/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-02-26 10:08:33] [config] after: 0e
[2022-02-26 10:08:33] [config] after-batches: 0
[2022-02-26 10:08:33] [config] after-epochs: 0
[2022-02-26 10:08:33] [config] all-caps-every: 0
[2022-02-26 10:08:33] [config] allow-unk: true
[2022-02-26 10:08:33] [config] authors: false
[2022-02-26 10:08:33] [config] beam-size: 6
[2022-02-26 10:08:33] [config] bert-class-symbol: "[CLS]"
[2022-02-26 10:08:33] [config] bert-mask-symbol: "[MASK]"
[2022-02-26 10:08:33] [config] bert-masking-fraction: 0.15
[2022-02-26 10:08:33] [config] bert-sep-symbol: "[SEP]"
[2022-02-26 10:08:33] [config] bert-train-type-embeddings: true
[2022-02-26 10:08:33] [config] bert-type-vocab-size: 2
[2022-02-26 10:08:33] [config] build-info: ""
[2022-02-26 10:08:33] [config] check-gradient-nan: false
[2022-02-26 10:08:33] [config] check-nan: false
[2022-02-26 10:08:33] [config] cite: false
[2022-02-26 10:08:33] [config] clip-norm: 0
[2022-02-26 10:08:33] [config] cost-scaling:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] cost-type: ce-mean-words
[2022-02-26 10:08:33] [config] cpu-threads: 0
[2022-02-26 10:08:33] [config] data-weighting: ""
[2022-02-26 10:08:33] [config] data-weighting-type: sentence
[2022-02-26 10:08:33] [config] dec-cell: gru
[2022-02-26 10:08:33] [config] dec-cell-base-depth: 2
[2022-02-26 10:08:33] [config] dec-cell-high-depth: 1
[2022-02-26 10:08:33] [config] dec-depth: 6
[2022-02-26 10:08:33] [config] devices:
[2022-02-26 10:08:33] [config]   - 0
[2022-02-26 10:08:33] [config]   - 1
[2022-02-26 10:08:33] [config] dim-emb: 1024
[2022-02-26 10:08:33] [config] dim-rnn: 1024
[2022-02-26 10:08:33] [config] dim-vocabs:
[2022-02-26 10:08:33] [config]   - 54728
[2022-02-26 10:08:33] [config]   - 54728
[2022-02-26 10:08:33] [config] disp-first: 0
[2022-02-26 10:08:33] [config] disp-freq: 10000
[2022-02-26 10:08:33] [config] disp-label-counts: true
[2022-02-26 10:08:33] [config] dropout-rnn: 0
[2022-02-26 10:08:33] [config] dropout-src: 0
[2022-02-26 10:08:33] [config] dropout-trg: 0
[2022-02-26 10:08:33] [config] dump-config: ""
[2022-02-26 10:08:33] [config] dynamic-gradient-scaling:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] early-stopping: 10
[2022-02-26 10:08:33] [config] early-stopping-on: first
[2022-02-26 10:08:33] [config] embedding-fix-src: false
[2022-02-26 10:08:33] [config] embedding-fix-trg: false
[2022-02-26 10:08:33] [config] embedding-normalization: false
[2022-02-26 10:08:33] [config] embedding-vectors:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] enc-cell: gru
[2022-02-26 10:08:33] [config] enc-cell-depth: 1
[2022-02-26 10:08:33] [config] enc-depth: 6
[2022-02-26 10:08:33] [config] enc-type: bidirectional
[2022-02-26 10:08:33] [config] english-title-case-every: 0
[2022-02-26 10:08:33] [config] exponential-smoothing: 0.0001
[2022-02-26 10:08:33] [config] factor-weight: 1
[2022-02-26 10:08:33] [config] factors-combine: sum
[2022-02-26 10:08:33] [config] factors-dim-emb: 0
[2022-02-26 10:08:33] [config] gradient-checkpointing: false
[2022-02-26 10:08:33] [config] gradient-norm-average-window: 100
[2022-02-26 10:08:33] [config] guided-alignment: none
[2022-02-26 10:08:33] [config] guided-alignment-cost: mse
[2022-02-26 10:08:33] [config] guided-alignment-weight: 0.1
[2022-02-26 10:08:33] [config] ignore-model-config: false
[2022-02-26 10:08:33] [config] input-types:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] interpolate-env-vars: false
[2022-02-26 10:08:33] [config] keep-best: true
[2022-02-26 10:08:33] [config] label-smoothing: 0.1
[2022-02-26 10:08:33] [config] layer-normalization: false
[2022-02-26 10:08:33] [config] learn-rate: 0.0002
[2022-02-26 10:08:33] [config] lemma-dependency: ""
[2022-02-26 10:08:33] [config] lemma-dim-emb: 0
[2022-02-26 10:08:33] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-02-26 10:08:33] [config] log-level: info
[2022-02-26 10:08:33] [config] log-time-zone: ""
[2022-02-26 10:08:33] [config] logical-epoch:
[2022-02-26 10:08:33] [config]   - 1e
[2022-02-26 10:08:33] [config]   - 0
[2022-02-26 10:08:33] [config] lr-decay: 0
[2022-02-26 10:08:33] [config] lr-decay-freq: 50000
[2022-02-26 10:08:33] [config] lr-decay-inv-sqrt:
[2022-02-26 10:08:33] [config]   - 8000
[2022-02-26 10:08:33] [config] lr-decay-repeat-warmup: false
[2022-02-26 10:08:33] [config] lr-decay-reset-optimizer: false
[2022-02-26 10:08:33] [config] lr-decay-start:
[2022-02-26 10:08:33] [config]   - 10
[2022-02-26 10:08:33] [config]   - 1
[2022-02-26 10:08:33] [config] lr-decay-strategy: epoch+stalled
[2022-02-26 10:08:33] [config] lr-report: false
[2022-02-26 10:08:33] [config] lr-warmup: 8000
[2022-02-26 10:08:33] [config] lr-warmup-at-reload: false
[2022-02-26 10:08:33] [config] lr-warmup-cycle: false
[2022-02-26 10:08:33] [config] lr-warmup-start-rate: 0
[2022-02-26 10:08:33] [config] max-length: 100
[2022-02-26 10:08:33] [config] max-length-crop: false
[2022-02-26 10:08:33] [config] max-length-factor: 3
[2022-02-26 10:08:33] [config] maxi-batch: 1000
[2022-02-26 10:08:33] [config] maxi-batch-sort: trg
[2022-02-26 10:08:33] [config] mini-batch: 1000
[2022-02-26 10:08:33] [config] mini-batch-fit: true
[2022-02-26 10:08:33] [config] mini-batch-fit-step: 10
[2022-02-26 10:08:33] [config] mini-batch-round-up: true
[2022-02-26 10:08:33] [config] mini-batch-track-lr: false
[2022-02-26 10:08:33] [config] mini-batch-warmup: 0
[2022-02-26 10:08:33] [config] mini-batch-words: 0
[2022-02-26 10:08:33] [config] mini-batch-words-ref: 0
[2022-02-26 10:08:33] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 10:08:33] [config] multi-loss-type: sum
[2022-02-26 10:08:33] [config] n-best: false
[2022-02-26 10:08:33] [config] no-nccl: false
[2022-02-26 10:08:33] [config] no-reload: false
[2022-02-26 10:08:33] [config] no-restore-corpus: true
[2022-02-26 10:08:33] [config] normalize: 1
[2022-02-26 10:08:33] [config] normalize-gradient: false
[2022-02-26 10:08:33] [config] num-devices: 0
[2022-02-26 10:08:33] [config] optimizer: adam
[2022-02-26 10:08:33] [config] optimizer-delay: 2
[2022-02-26 10:08:33] [config] optimizer-params:
[2022-02-26 10:08:33] [config]   - 0.9
[2022-02-26 10:08:33] [config]   - 0.998
[2022-02-26 10:08:33] [config]   - 1e-09
[2022-02-26 10:08:33] [config] output-omit-bias: false
[2022-02-26 10:08:33] [config] overwrite: true
[2022-02-26 10:08:33] [config] precision:
[2022-02-26 10:08:33] [config]   - float32
[2022-02-26 10:08:33] [config]   - float32
[2022-02-26 10:08:33] [config] pretrained-model: ""
[2022-02-26 10:08:33] [config] quantize-biases: false
[2022-02-26 10:08:33] [config] quantize-bits: 0
[2022-02-26 10:08:33] [config] quantize-log-based: false
[2022-02-26 10:08:33] [config] quantize-optimization-steps: 0
[2022-02-26 10:08:33] [config] quiet: false
[2022-02-26 10:08:33] [config] quiet-translation: false
[2022-02-26 10:08:33] [config] relative-paths: false
[2022-02-26 10:08:33] [config] right-left: false
[2022-02-26 10:08:33] [config] save-freq: 10000
[2022-02-26 10:08:33] [config] seed: 1111
[2022-02-26 10:08:33] [config] sentencepiece-alphas:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] sentencepiece-max-lines: 2000000
[2022-02-26 10:08:33] [config] sentencepiece-options: ""
[2022-02-26 10:08:33] [config] sharding: local
[2022-02-26 10:08:33] [config] shuffle: batches
[2022-02-26 10:08:33] [config] shuffle-in-ram: false
[2022-02-26 10:08:33] [config] sigterm: save-and-exit
[2022-02-26 10:08:33] [config] skip: false
[2022-02-26 10:08:33] [config] sqlite: ""
[2022-02-26 10:08:33] [config] sqlite-drop: false
[2022-02-26 10:08:33] [config] sync-freq: 200u
[2022-02-26 10:08:33] [config] sync-sgd: true
[2022-02-26 10:08:33] [config] tempdir: /run/nvme/job_10746062/tmp
[2022-02-26 10:08:33] [config] tied-embeddings: false
[2022-02-26 10:08:33] [config] tied-embeddings-all: true
[2022-02-26 10:08:33] [config] tied-embeddings-src: false
[2022-02-26 10:08:33] [config] train-embedder-rank:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] train-sets:
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-02-26 10:08:33] [config] transformer-aan-activation: swish
[2022-02-26 10:08:33] [config] transformer-aan-depth: 2
[2022-02-26 10:08:33] [config] transformer-aan-nogate: false
[2022-02-26 10:08:33] [config] transformer-decoder-autoreg: self-attention
[2022-02-26 10:08:33] [config] transformer-depth-scaling: false
[2022-02-26 10:08:33] [config] transformer-dim-aan: 2048
[2022-02-26 10:08:33] [config] transformer-dim-ffn: 4096
[2022-02-26 10:08:33] [config] transformer-dropout: 0.1
[2022-02-26 10:08:33] [config] transformer-dropout-attention: 0
[2022-02-26 10:08:33] [config] transformer-dropout-ffn: 0
[2022-02-26 10:08:33] [config] transformer-ffn-activation: relu
[2022-02-26 10:08:33] [config] transformer-ffn-depth: 2
[2022-02-26 10:08:33] [config] transformer-guided-alignment-layer: last
[2022-02-26 10:08:33] [config] transformer-heads: 16
[2022-02-26 10:08:33] [config] transformer-no-projection: false
[2022-02-26 10:08:33] [config] transformer-pool: false
[2022-02-26 10:08:33] [config] transformer-postprocess: dan
[2022-02-26 10:08:33] [config] transformer-postprocess-emb: d
[2022-02-26 10:08:33] [config] transformer-postprocess-top: ""
[2022-02-26 10:08:33] [config] transformer-preprocess: ""
[2022-02-26 10:08:33] [config] transformer-tied-layers:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] transformer-train-position-embeddings: false
[2022-02-26 10:08:33] [config] tsv: false
[2022-02-26 10:08:33] [config] tsv-fields: 0
[2022-02-26 10:08:33] [config] type: transformer
[2022-02-26 10:08:33] [config] ulr: false
[2022-02-26 10:08:33] [config] ulr-dim-emb: 0
[2022-02-26 10:08:33] [config] ulr-dropout: 0
[2022-02-26 10:08:33] [config] ulr-keys-vectors: ""
[2022-02-26 10:08:33] [config] ulr-query-vectors: ""
[2022-02-26 10:08:33] [config] ulr-softmax-temperature: 1
[2022-02-26 10:08:33] [config] ulr-trainable-transformation: false
[2022-02-26 10:08:33] [config] unlikelihood-loss: false
[2022-02-26 10:08:33] [config] valid-freq: 10000
[2022-02-26 10:08:33] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-02-26 10:08:33] [config] valid-max-length: 100
[2022-02-26 10:08:33] [config] valid-metrics:
[2022-02-26 10:08:33] [config]   - perplexity
[2022-02-26 10:08:33] [config] valid-mini-batch: 16
[2022-02-26 10:08:33] [config] valid-reset-stalled: false
[2022-02-26 10:08:33] [config] valid-script-args:
[2022-02-26 10:08:33] [config]   []
[2022-02-26 10:08:33] [config] valid-script-path: ""
[2022-02-26 10:08:33] [config] valid-sets:
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-02-26 10:08:33] [config] valid-translation-output: ""
[2022-02-26 10:08:33] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-26 10:08:33] [config] vocabs:
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-26 10:08:33] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-26 10:08:33] [config] word-penalty: 0
[2022-02-26 10:08:33] [config] word-scores: false
[2022-02-26 10:08:33] [config] workspace: 15000
[2022-02-26 10:08:33] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-02-26 10:08:33] Using synchronous SGD
[2022-02-26 10:08:33] [comm] Compiled without MPI support. Running as a single process on r18g05.bullx
[2022-02-26 10:08:33] Synced seed 1111
[2022-02-26 10:08:33] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-26 10:08:34] [data] Setting vocabulary size for input 0 to 54,728
[2022-02-26 10:08:34] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-02-26 10:08:34] [data] Setting vocabulary size for input 1 to 54,728
[2022-02-26 10:08:34] [batching] Collecting statistics for batch fitting with step size 10
[2022-02-26 10:08:35] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-26 10:08:37] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-26 10:08:37] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-26 10:08:37] [comm] Using global sharding
[2022-02-26 10:08:39] [comm] NCCLCommunicators constructed successfully
[2022-02-26 10:08:39] [training] Using 2 GPUs
[2022-02-26 10:08:39] [logits] Applying loss function for 1 factor(s)
[2022-02-26 10:08:39] [memory] Reserving 886 MB, device gpu0
[2022-02-26 10:08:41] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-02-26 10:08:41] [memory] Reserving 886 MB, device gpu0
[2022-02-26 10:09:04] [batching] Done. Typical MB size is 27,536 target words
[2022-02-26 10:09:04] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-02-26 10:09:05] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-02-26 10:09:05] [comm] Using NCCL 2.8.3 for GPU communication
[2022-02-26 10:09:05] [comm] Using global sharding
[2022-02-26 10:09:08] [comm] NCCLCommunicators constructed successfully
[2022-02-26 10:09:08] [training] Using 2 GPUs
[2022-02-26 10:09:08] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 10:09:10] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 10:09:18] Allocating memory for general optimizer shards
[2022-02-26 10:09:18] [memory] Reserving 443 MB, device gpu0
[2022-02-26 10:09:18] [memory] Reserving 443 MB, device gpu1
[2022-02-26 10:09:18] Loading Adam parameters
[2022-02-26 10:09:19] [memory] Reserving 886 MB, device gpu0
[2022-02-26 10:09:19] [memory] Reserving 886 MB, device gpu1
[2022-02-26 10:09:19] [memory] Reserving 886 MB, device gpu0
[2022-02-26 10:09:20] [memory] Reserving 886 MB, device gpu1
[2022-02-26 10:09:20] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 10:09:20] Training started
[2022-02-26 10:09:43] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-02-26 10:09:43] [memory] Reserving 886 MB, device gpu0
[2022-02-26 10:09:43] [memory] Reserving 886 MB, device gpu1
[2022-02-26 10:09:46] Parameter type float32, optimization type float32, casting types false
[2022-02-26 13:43:01] Ep. 1 : Up. 440000 : Sen. 9,157,155 : Cost 2.39307332 : Time 12836.58s : 16000.02 words/s : gNorm 0.5970
[2022-02-26 13:43:01] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 13:43:05] Saving Adam parameters
[2022-02-26 13:43:08] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 13:43:18] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 13:43:20] [valid] Ep. 1 : Up. 440000 : perplexity : 4.41144 : new best
[2022-02-26 17:16:15] Ep. 1 : Up. 450000 : Sen. 18,299,011 : Cost 2.39052749 : Time 12793.67s : 16068.44 words/s : gNorm 0.5530
[2022-02-26 17:16:15] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 17:16:18] Saving Adam parameters
[2022-02-26 17:16:22] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 17:16:31] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 17:16:33] [valid] Ep. 1 : Up. 450000 : perplexity : 4.4077 : new best
[2022-02-26 20:49:19] Ep. 1 : Up. 460000 : Sen. 27,429,933 : Cost 2.38910532 : Time 12783.94s : 16069.20 words/s : gNorm 0.5111
[2022-02-26 20:49:19] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-26 20:49:22] Saving Adam parameters
[2022-02-26 20:49:26] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-26 20:49:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-26 20:49:36] [valid] Ep. 1 : Up. 460000 : perplexity : 4.40258 : new best
[2022-02-27 00:22:17] Ep. 1 : Up. 470000 : Sen. 36,599,477 : Cost 2.38830543 : Time 12777.87s : 16082.18 words/s : gNorm 0.5445
[2022-02-27 00:22:17] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 00:22:20] Saving Adam parameters
[2022-02-27 00:22:23] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 00:22:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 00:22:34] [valid] Ep. 1 : Up. 470000 : perplexity : 4.39902 : new best
[2022-02-27 03:55:17] Ep. 1 : Up. 480000 : Sen. 45,732,248 : Cost 2.38734579 : Time 12780.06s : 16063.42 words/s : gNorm 0.5363
[2022-02-27 03:55:17] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 03:55:20] Saving Adam parameters
[2022-02-27 03:55:24] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 03:55:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 03:55:34] [valid] Ep. 1 : Up. 480000 : perplexity : 4.3955 : new best
[2022-02-27 07:28:21] Ep. 1 : Up. 490000 : Sen. 54,887,710 : Cost 2.38593602 : Time 12784.32s : 16068.55 words/s : gNorm 0.5612
[2022-02-27 07:28:21] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 07:28:25] Saving Adam parameters
[2022-02-27 07:28:28] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 07:28:36] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 07:28:38] [valid] Ep. 1 : Up. 490000 : perplexity : 4.38775 : new best
[2022-02-27 11:01:22] Ep. 1 : Up. 500000 : Sen. 64,018,771 : Cost 2.38400292 : Time 12781.03s : 16071.85 words/s : gNorm 0.5868
[2022-02-27 11:01:22] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 11:01:29] Saving Adam parameters
[2022-02-27 11:01:36] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 11:01:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 11:01:48] [valid] Ep. 1 : Up. 500000 : perplexity : 4.38021 : new best
[2022-02-27 14:34:24] Ep. 1 : Up. 510000 : Sen. 73,175,796 : Cost 2.38350224 : Time 12781.15s : 16081.37 words/s : gNorm 0.5383
[2022-02-27 14:34:24] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 14:34:27] Saving Adam parameters
[2022-02-27 14:34:31] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 14:34:40] [valid] Ep. 1 : Up. 510000 : perplexity : 4.38064 : stalled 1 times (last best: 4.38021)
[2022-02-27 18:07:19] Ep. 1 : Up. 520000 : Sen. 82,321,838 : Cost 2.38202763 : Time 12775.00s : 16078.64 words/s : gNorm 0.5520
[2022-02-27 18:07:19] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 18:07:22] Saving Adam parameters
[2022-02-27 18:07:26] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 18:07:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 18:07:36] [valid] Ep. 1 : Up. 520000 : perplexity : 4.37633 : new best
[2022-02-27 21:40:41] Ep. 1 : Up. 530000 : Sen. 91,465,281 : Cost 2.38161516 : Time 12802.21s : 16045.82 words/s : gNorm 0.6120
[2022-02-27 21:40:41] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-27 21:40:44] Saving Adam parameters
[2022-02-27 21:40:48] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-27 21:40:56] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-27 21:40:58] [valid] Ep. 1 : Up. 530000 : perplexity : 4.36795 : new best
[2022-02-28 01:14:18] Ep. 1 : Up. 540000 : Sen. 100,615,039 : Cost 2.38010931 : Time 12816.81s : 16035.11 words/s : gNorm 0.5646
[2022-02-28 01:14:18] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 01:14:21] Saving Adam parameters
[2022-02-28 01:14:25] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 01:14:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 01:14:35] [valid] Ep. 1 : Up. 540000 : perplexity : 4.36507 : new best
[2022-02-28 04:47:31] Ep. 1 : Up. 550000 : Sen. 109,738,459 : Cost 2.37852836 : Time 12793.40s : 16060.60 words/s : gNorm 0.6229
[2022-02-28 04:47:31] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 04:47:34] Saving Adam parameters
[2022-02-28 04:47:38] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 04:47:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 04:47:48] [valid] Ep. 1 : Up. 550000 : perplexity : 4.3606 : new best
[2022-02-28 08:20:30] Ep. 1 : Up. 560000 : Sen. 118,905,778 : Cost 2.37900376 : Time 12778.37s : 16071.99 words/s : gNorm 0.5759
[2022-02-28 08:20:30] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 08:20:33] Saving Adam parameters
[2022-02-28 08:20:37] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 08:20:45] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 08:20:47] [valid] Ep. 1 : Up. 560000 : perplexity : 4.3536 : new best
[2022-02-28 11:54:13] Ep. 1 : Up. 570000 : Sen. 128,053,008 : Cost 2.37767410 : Time 12823.56s : 16024.25 words/s : gNorm 0.5823
[2022-02-28 11:54:13] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 11:54:17] Saving Adam parameters
[2022-02-28 11:54:21] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 11:54:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 11:54:34] [valid] Ep. 1 : Up. 570000 : perplexity : 4.34716 : new best
[2022-02-28 15:27:20] Ep. 1 : Up. 580000 : Sen. 137,193,522 : Cost 2.37632680 : Time 12786.75s : 16061.55 words/s : gNorm 0.5585
[2022-02-28 15:27:20] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 15:27:24] Saving Adam parameters
[2022-02-28 15:27:27] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 15:27:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 15:27:37] [valid] Ep. 1 : Up. 580000 : perplexity : 4.34155 : new best
[2022-02-28 19:00:20] Ep. 1 : Up. 590000 : Sen. 146,351,606 : Cost 2.37678671 : Time 12780.34s : 16071.75 words/s : gNorm 0.6324
[2022-02-28 19:00:21] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 19:00:24] Saving Adam parameters
[2022-02-28 19:00:27] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 19:00:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 19:00:37] [valid] Ep. 1 : Up. 590000 : perplexity : 4.33773 : new best
[2022-02-28 22:33:19] Ep. 1 : Up. 600000 : Sen. 155,474,105 : Cost 2.37493825 : Time 12778.55s : 16066.46 words/s : gNorm 0.5819
[2022-02-28 22:33:19] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-02-28 22:33:23] Saving Adam parameters
[2022-02-28 22:33:26] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-02-28 22:33:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-02-28 22:33:37] [valid] Ep. 1 : Up. 600000 : perplexity : 4.3335 : new best
[2022-03-01 02:06:42] Ep. 1 : Up. 610000 : Sen. 164,619,953 : Cost 2.37351370 : Time 12802.66s : 16050.03 words/s : gNorm 0.5536
[2022-03-01 02:06:42] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 02:06:45] Saving Adam parameters
[2022-03-01 02:06:49] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 02:06:57] [valid] Ep. 1 : Up. 610000 : perplexity : 4.3345 : stalled 1 times (last best: 4.3335)
[2022-03-01 05:39:42] Ep. 1 : Up. 620000 : Sen. 173,759,503 : Cost 2.37325811 : Time 12780.20s : 16081.94 words/s : gNorm 0.5971
[2022-03-01 05:39:42] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 05:39:46] Saving Adam parameters
[2022-03-01 05:39:49] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 05:39:57] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-01 05:40:00] [valid] Ep. 1 : Up. 620000 : perplexity : 4.33205 : new best
[2022-03-01 09:12:39] Ep. 1 : Up. 630000 : Sen. 182,912,066 : Cost 2.37356091 : Time 12777.10s : 16075.53 words/s : gNorm 0.6111
[2022-03-01 09:12:39] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 09:12:43] Saving Adam parameters
[2022-03-01 09:12:46] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 09:12:55] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-01 09:12:57] [valid] Ep. 1 : Up. 630000 : perplexity : 4.32807 : new best
[2022-03-01 14:08:13] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-01 14:08:13] [marian] Running on r14g08.bullx as process 17010 with command line:
[2022-03-01 14:08:13] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10787451/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-03-01 14:08:16] [config] after: 0e
[2022-03-01 14:08:16] [config] after-batches: 0
[2022-03-01 14:08:16] [config] after-epochs: 0
[2022-03-01 14:08:16] [config] all-caps-every: 0
[2022-03-01 14:08:16] [config] allow-unk: true
[2022-03-01 14:08:16] [config] authors: false
[2022-03-01 14:08:16] [config] beam-size: 6
[2022-03-01 14:08:16] [config] bert-class-symbol: "[CLS]"
[2022-03-01 14:08:16] [config] bert-mask-symbol: "[MASK]"
[2022-03-01 14:08:16] [config] bert-masking-fraction: 0.15
[2022-03-01 14:08:16] [config] bert-sep-symbol: "[SEP]"
[2022-03-01 14:08:16] [config] bert-train-type-embeddings: true
[2022-03-01 14:08:16] [config] bert-type-vocab-size: 2
[2022-03-01 14:08:16] [config] build-info: ""
[2022-03-01 14:08:16] [config] check-gradient-nan: false
[2022-03-01 14:08:16] [config] check-nan: false
[2022-03-01 14:08:16] [config] cite: false
[2022-03-01 14:08:16] [config] clip-norm: 0
[2022-03-01 14:08:16] [config] cost-scaling:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] cost-type: ce-mean-words
[2022-03-01 14:08:16] [config] cpu-threads: 0
[2022-03-01 14:08:16] [config] data-weighting: ""
[2022-03-01 14:08:16] [config] data-weighting-type: sentence
[2022-03-01 14:08:16] [config] dec-cell: gru
[2022-03-01 14:08:16] [config] dec-cell-base-depth: 2
[2022-03-01 14:08:16] [config] dec-cell-high-depth: 1
[2022-03-01 14:08:16] [config] dec-depth: 6
[2022-03-01 14:08:16] [config] devices:
[2022-03-01 14:08:16] [config]   - 0
[2022-03-01 14:08:16] [config]   - 1
[2022-03-01 14:08:16] [config] dim-emb: 1024
[2022-03-01 14:08:16] [config] dim-rnn: 1024
[2022-03-01 14:08:16] [config] dim-vocabs:
[2022-03-01 14:08:16] [config]   - 54728
[2022-03-01 14:08:16] [config]   - 54728
[2022-03-01 14:08:16] [config] disp-first: 0
[2022-03-01 14:08:16] [config] disp-freq: 10000
[2022-03-01 14:08:16] [config] disp-label-counts: true
[2022-03-01 14:08:16] [config] dropout-rnn: 0
[2022-03-01 14:08:16] [config] dropout-src: 0
[2022-03-01 14:08:16] [config] dropout-trg: 0
[2022-03-01 14:08:16] [config] dump-config: ""
[2022-03-01 14:08:16] [config] dynamic-gradient-scaling:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] early-stopping: 10
[2022-03-01 14:08:16] [config] early-stopping-on: first
[2022-03-01 14:08:16] [config] embedding-fix-src: false
[2022-03-01 14:08:16] [config] embedding-fix-trg: false
[2022-03-01 14:08:16] [config] embedding-normalization: false
[2022-03-01 14:08:16] [config] embedding-vectors:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] enc-cell: gru
[2022-03-01 14:08:16] [config] enc-cell-depth: 1
[2022-03-01 14:08:16] [config] enc-depth: 6
[2022-03-01 14:08:16] [config] enc-type: bidirectional
[2022-03-01 14:08:16] [config] english-title-case-every: 0
[2022-03-01 14:08:16] [config] exponential-smoothing: 0.0001
[2022-03-01 14:08:16] [config] factor-weight: 1
[2022-03-01 14:08:16] [config] factors-combine: sum
[2022-03-01 14:08:16] [config] factors-dim-emb: 0
[2022-03-01 14:08:16] [config] gradient-checkpointing: false
[2022-03-01 14:08:16] [config] gradient-norm-average-window: 100
[2022-03-01 14:08:16] [config] guided-alignment: none
[2022-03-01 14:08:16] [config] guided-alignment-cost: mse
[2022-03-01 14:08:16] [config] guided-alignment-weight: 0.1
[2022-03-01 14:08:16] [config] ignore-model-config: false
[2022-03-01 14:08:16] [config] input-types:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] interpolate-env-vars: false
[2022-03-01 14:08:16] [config] keep-best: true
[2022-03-01 14:08:16] [config] label-smoothing: 0.1
[2022-03-01 14:08:16] [config] layer-normalization: false
[2022-03-01 14:08:16] [config] learn-rate: 0.0002
[2022-03-01 14:08:16] [config] lemma-dependency: ""
[2022-03-01 14:08:16] [config] lemma-dim-emb: 0
[2022-03-01 14:08:16] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-03-01 14:08:16] [config] log-level: info
[2022-03-01 14:08:16] [config] log-time-zone: ""
[2022-03-01 14:08:16] [config] logical-epoch:
[2022-03-01 14:08:16] [config]   - 1e
[2022-03-01 14:08:16] [config]   - 0
[2022-03-01 14:08:16] [config] lr-decay: 0
[2022-03-01 14:08:16] [config] lr-decay-freq: 50000
[2022-03-01 14:08:16] [config] lr-decay-inv-sqrt:
[2022-03-01 14:08:16] [config]   - 8000
[2022-03-01 14:08:16] [config] lr-decay-repeat-warmup: false
[2022-03-01 14:08:16] [config] lr-decay-reset-optimizer: false
[2022-03-01 14:08:16] [config] lr-decay-start:
[2022-03-01 14:08:16] [config]   - 10
[2022-03-01 14:08:16] [config]   - 1
[2022-03-01 14:08:16] [config] lr-decay-strategy: epoch+stalled
[2022-03-01 14:08:16] [config] lr-report: false
[2022-03-01 14:08:16] [config] lr-warmup: 8000
[2022-03-01 14:08:16] [config] lr-warmup-at-reload: false
[2022-03-01 14:08:16] [config] lr-warmup-cycle: false
[2022-03-01 14:08:16] [config] lr-warmup-start-rate: 0
[2022-03-01 14:08:16] [config] max-length: 100
[2022-03-01 14:08:16] [config] max-length-crop: false
[2022-03-01 14:08:16] [config] max-length-factor: 3
[2022-03-01 14:08:16] [config] maxi-batch: 1000
[2022-03-01 14:08:16] [config] maxi-batch-sort: trg
[2022-03-01 14:08:16] [config] mini-batch: 1000
[2022-03-01 14:08:16] [config] mini-batch-fit: true
[2022-03-01 14:08:16] [config] mini-batch-fit-step: 10
[2022-03-01 14:08:16] [config] mini-batch-round-up: true
[2022-03-01 14:08:16] [config] mini-batch-track-lr: false
[2022-03-01 14:08:16] [config] mini-batch-warmup: 0
[2022-03-01 14:08:16] [config] mini-batch-words: 0
[2022-03-01 14:08:16] [config] mini-batch-words-ref: 0
[2022-03-01 14:08:16] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 14:08:16] [config] multi-loss-type: sum
[2022-03-01 14:08:16] [config] n-best: false
[2022-03-01 14:08:16] [config] no-nccl: false
[2022-03-01 14:08:16] [config] no-reload: false
[2022-03-01 14:08:16] [config] no-restore-corpus: true
[2022-03-01 14:08:16] [config] normalize: 1
[2022-03-01 14:08:16] [config] normalize-gradient: false
[2022-03-01 14:08:16] [config] num-devices: 0
[2022-03-01 14:08:16] [config] optimizer: adam
[2022-03-01 14:08:16] [config] optimizer-delay: 2
[2022-03-01 14:08:16] [config] optimizer-params:
[2022-03-01 14:08:16] [config]   - 0.9
[2022-03-01 14:08:16] [config]   - 0.998
[2022-03-01 14:08:16] [config]   - 1e-09
[2022-03-01 14:08:16] [config] output-omit-bias: false
[2022-03-01 14:08:16] [config] overwrite: true
[2022-03-01 14:08:16] [config] precision:
[2022-03-01 14:08:16] [config]   - float32
[2022-03-01 14:08:16] [config]   - float32
[2022-03-01 14:08:16] [config] pretrained-model: ""
[2022-03-01 14:08:16] [config] quantize-biases: false
[2022-03-01 14:08:16] [config] quantize-bits: 0
[2022-03-01 14:08:16] [config] quantize-log-based: false
[2022-03-01 14:08:16] [config] quantize-optimization-steps: 0
[2022-03-01 14:08:16] [config] quiet: false
[2022-03-01 14:08:16] [config] quiet-translation: false
[2022-03-01 14:08:16] [config] relative-paths: false
[2022-03-01 14:08:16] [config] right-left: false
[2022-03-01 14:08:16] [config] save-freq: 10000
[2022-03-01 14:08:16] [config] seed: 1111
[2022-03-01 14:08:16] [config] sentencepiece-alphas:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] sentencepiece-max-lines: 2000000
[2022-03-01 14:08:16] [config] sentencepiece-options: ""
[2022-03-01 14:08:16] [config] sharding: local
[2022-03-01 14:08:16] [config] shuffle: batches
[2022-03-01 14:08:16] [config] shuffle-in-ram: false
[2022-03-01 14:08:16] [config] sigterm: save-and-exit
[2022-03-01 14:08:16] [config] skip: false
[2022-03-01 14:08:16] [config] sqlite: ""
[2022-03-01 14:08:16] [config] sqlite-drop: false
[2022-03-01 14:08:16] [config] sync-freq: 200u
[2022-03-01 14:08:16] [config] sync-sgd: true
[2022-03-01 14:08:16] [config] tempdir: /run/nvme/job_10787451/tmp
[2022-03-01 14:08:16] [config] tied-embeddings: false
[2022-03-01 14:08:16] [config] tied-embeddings-all: true
[2022-03-01 14:08:16] [config] tied-embeddings-src: false
[2022-03-01 14:08:16] [config] train-embedder-rank:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] train-sets:
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-03-01 14:08:16] [config] transformer-aan-activation: swish
[2022-03-01 14:08:16] [config] transformer-aan-depth: 2
[2022-03-01 14:08:16] [config] transformer-aan-nogate: false
[2022-03-01 14:08:16] [config] transformer-decoder-autoreg: self-attention
[2022-03-01 14:08:16] [config] transformer-depth-scaling: false
[2022-03-01 14:08:16] [config] transformer-dim-aan: 2048
[2022-03-01 14:08:16] [config] transformer-dim-ffn: 4096
[2022-03-01 14:08:16] [config] transformer-dropout: 0.1
[2022-03-01 14:08:16] [config] transformer-dropout-attention: 0
[2022-03-01 14:08:16] [config] transformer-dropout-ffn: 0
[2022-03-01 14:08:16] [config] transformer-ffn-activation: relu
[2022-03-01 14:08:16] [config] transformer-ffn-depth: 2
[2022-03-01 14:08:16] [config] transformer-guided-alignment-layer: last
[2022-03-01 14:08:16] [config] transformer-heads: 16
[2022-03-01 14:08:16] [config] transformer-no-projection: false
[2022-03-01 14:08:16] [config] transformer-pool: false
[2022-03-01 14:08:16] [config] transformer-postprocess: dan
[2022-03-01 14:08:16] [config] transformer-postprocess-emb: d
[2022-03-01 14:08:16] [config] transformer-postprocess-top: ""
[2022-03-01 14:08:16] [config] transformer-preprocess: ""
[2022-03-01 14:08:16] [config] transformer-tied-layers:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] transformer-train-position-embeddings: false
[2022-03-01 14:08:16] [config] tsv: false
[2022-03-01 14:08:16] [config] tsv-fields: 0
[2022-03-01 14:08:16] [config] type: transformer
[2022-03-01 14:08:16] [config] ulr: false
[2022-03-01 14:08:16] [config] ulr-dim-emb: 0
[2022-03-01 14:08:16] [config] ulr-dropout: 0
[2022-03-01 14:08:16] [config] ulr-keys-vectors: ""
[2022-03-01 14:08:16] [config] ulr-query-vectors: ""
[2022-03-01 14:08:16] [config] ulr-softmax-temperature: 1
[2022-03-01 14:08:16] [config] ulr-trainable-transformation: false
[2022-03-01 14:08:16] [config] unlikelihood-loss: false
[2022-03-01 14:08:16] [config] valid-freq: 10000
[2022-03-01 14:08:16] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-03-01 14:08:16] [config] valid-max-length: 100
[2022-03-01 14:08:16] [config] valid-metrics:
[2022-03-01 14:08:16] [config]   - perplexity
[2022-03-01 14:08:16] [config] valid-mini-batch: 16
[2022-03-01 14:08:16] [config] valid-reset-stalled: false
[2022-03-01 14:08:16] [config] valid-script-args:
[2022-03-01 14:08:16] [config]   []
[2022-03-01 14:08:16] [config] valid-script-path: ""
[2022-03-01 14:08:16] [config] valid-sets:
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-03-01 14:08:16] [config] valid-translation-output: ""
[2022-03-01 14:08:16] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-01 14:08:16] [config] vocabs:
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-01 14:08:16] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-01 14:08:16] [config] word-penalty: 0
[2022-03-01 14:08:16] [config] word-scores: false
[2022-03-01 14:08:16] [config] workspace: 15000
[2022-03-01 14:08:16] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-01 14:08:17] Using synchronous SGD
[2022-03-01 14:08:17] [comm] Compiled without MPI support. Running as a single process on r14g08.bullx
[2022-03-01 14:08:17] Synced seed 1111
[2022-03-01 14:08:17] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-01 14:08:18] [data] Setting vocabulary size for input 0 to 54,728
[2022-03-01 14:08:18] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-01 14:08:18] [data] Setting vocabulary size for input 1 to 54,728
[2022-03-01 14:08:18] [batching] Collecting statistics for batch fitting with step size 10
[2022-03-01 14:08:23] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-01 14:08:25] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-01 14:08:25] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-01 14:08:25] [comm] Using global sharding
[2022-03-01 14:08:26] [comm] NCCLCommunicators constructed successfully
[2022-03-01 14:08:26] [training] Using 2 GPUs
[2022-03-01 14:08:27] [logits] Applying loss function for 1 factor(s)
[2022-03-01 14:08:27] [memory] Reserving 886 MB, device gpu0
[2022-03-01 14:08:35] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-03-01 14:08:36] [memory] Reserving 886 MB, device gpu0
[2022-03-01 14:08:59] [batching] Done. Typical MB size is 27,536 target words
[2022-03-01 14:08:59] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-01 14:08:59] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-01 14:08:59] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-01 14:08:59] [comm] Using global sharding
[2022-03-01 14:09:00] [comm] NCCLCommunicators constructed successfully
[2022-03-01 14:09:00] [training] Using 2 GPUs
[2022-03-01 14:09:00] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 14:09:02] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 14:09:18] Allocating memory for general optimizer shards
[2022-03-01 14:09:18] [memory] Reserving 443 MB, device gpu0
[2022-03-01 14:09:18] [memory] Reserving 443 MB, device gpu1
[2022-03-01 14:09:18] Loading Adam parameters
[2022-03-01 14:09:19] [memory] Reserving 886 MB, device gpu0
[2022-03-01 14:09:19] [memory] Reserving 886 MB, device gpu1
[2022-03-01 14:09:19] [memory] Reserving 886 MB, device gpu0
[2022-03-01 14:09:19] [memory] Reserving 886 MB, device gpu1
[2022-03-01 14:09:20] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 14:09:20] Training started
[2022-03-01 14:09:43] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-03-01 14:09:43] [memory] Reserving 886 MB, device gpu0
[2022-03-01 14:09:43] [memory] Reserving 886 MB, device gpu1
[2022-03-01 14:09:45] Parameter type float32, optimization type float32, casting types false
[2022-03-01 17:42:46] Ep. 1 : Up. 640000 : Sen. 9,157,155 : Cost 2.37068605 : Time 12826.67s : 16012.38 words/s : gNorm 0.6419
[2022-03-01 17:42:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 17:42:51] Saving Adam parameters
[2022-03-01 17:42:54] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 17:43:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-01 17:43:05] [valid] Ep. 1 : Up. 640000 : perplexity : 4.32731 : new best
[2022-03-01 21:15:58] Ep. 1 : Up. 650000 : Sen. 18,299,011 : Cost 2.36878681 : Time 12791.88s : 16070.68 words/s : gNorm 0.5920
[2022-03-01 21:15:58] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-01 21:16:01] Saving Adam parameters
[2022-03-01 21:16:05] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-01 21:16:13] [valid] Ep. 1 : Up. 650000 : perplexity : 4.3298 : stalled 1 times (last best: 4.32731)
[2022-03-02 00:48:56] Ep. 1 : Up. 660000 : Sen. 27,429,933 : Cost 2.36795211 : Time 12778.03s : 16076.64 words/s : gNorm 0.5455
[2022-03-02 00:48:56] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 00:49:00] Saving Adam parameters
[2022-03-02 00:49:03] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 00:49:11] [valid] Ep. 1 : Up. 660000 : perplexity : 4.32793 : stalled 2 times (last best: 4.32731)
[2022-03-02 04:21:48] Ep. 1 : Up. 670000 : Sen. 36,599,477 : Cost 2.36768365 : Time 12771.46s : 16090.27 words/s : gNorm 0.5818
[2022-03-02 04:21:48] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 04:21:51] Saving Adam parameters
[2022-03-02 04:21:54] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 04:22:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 04:22:04] [valid] Ep. 1 : Up. 670000 : perplexity : 4.3262 : new best
[2022-03-02 07:54:36] Ep. 1 : Up. 680000 : Sen. 45,732,248 : Cost 2.36722708 : Time 12768.69s : 16077.73 words/s : gNorm 0.5720
[2022-03-02 07:54:36] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 07:54:40] Saving Adam parameters
[2022-03-02 07:54:43] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 07:54:51] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 07:54:53] [valid] Ep. 1 : Up. 680000 : perplexity : 4.32421 : new best
[2022-03-02 11:27:32] Ep. 1 : Up. 690000 : Sen. 54,887,710 : Cost 2.36632204 : Time 12775.30s : 16079.90 words/s : gNorm 0.5985
[2022-03-02 11:27:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 11:27:35] Saving Adam parameters
[2022-03-02 11:27:38] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 11:27:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 11:27:48] [valid] Ep. 1 : Up. 690000 : perplexity : 4.31871 : new best
[2022-03-02 15:00:35] Ep. 1 : Up. 700000 : Sen. 64,018,771 : Cost 2.36482692 : Time 12782.67s : 16069.80 words/s : gNorm 0.6234
[2022-03-02 15:00:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 15:00:42] Saving Adam parameters
[2022-03-02 15:00:49] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 15:00:58] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 15:01:01] [valid] Ep. 1 : Up. 700000 : perplexity : 4.31279 : new best
[2022-03-02 18:34:00] Ep. 1 : Up. 710000 : Sen. 73,175,796 : Cost 2.36479592 : Time 12805.38s : 16050.94 words/s : gNorm 0.5752
[2022-03-02 18:34:00] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 18:34:04] Saving Adam parameters
[2022-03-02 18:34:07] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 18:34:16] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 18:34:18] [valid] Ep. 1 : Up. 710000 : perplexity : 4.31219 : new best
[2022-03-02 22:06:59] Ep. 1 : Up. 720000 : Sen. 82,321,838 : Cost 2.36375380 : Time 12779.24s : 16073.30 words/s : gNorm 0.5874
[2022-03-02 22:07:00] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-02 22:07:03] Saving Adam parameters
[2022-03-02 22:07:07] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-02 22:07:15] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-02 22:07:17] [valid] Ep. 1 : Up. 720000 : perplexity : 4.30883 : new best
[2022-03-03 01:39:54] Ep. 1 : Up. 730000 : Sen. 91,465,281 : Cost 2.36372185 : Time 12774.79s : 16080.26 words/s : gNorm 0.6517
[2022-03-03 01:39:54] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 01:39:57] Saving Adam parameters
[2022-03-03 01:40:01] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 01:40:09] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-03 01:40:11] [valid] Ep. 1 : Up. 730000 : perplexity : 4.3025 : new best
[2022-03-03 05:12:52] Ep. 1 : Up. 740000 : Sen. 100,615,039 : Cost 2.36256385 : Time 12777.32s : 16084.67 words/s : gNorm 0.5983
[2022-03-03 05:12:52] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 05:12:56] Saving Adam parameters
[2022-03-03 05:12:59] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 05:13:15] [valid] Ep. 1 : Up. 740000 : perplexity : 4.30299 : stalled 1 times (last best: 4.3025)
[2022-03-03 08:45:49] Ep. 1 : Up. 750000 : Sen. 109,738,459 : Cost 2.36137342 : Time 12776.52s : 16081.82 words/s : gNorm 0.6627
[2022-03-03 08:45:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 08:45:53] Saving Adam parameters
[2022-03-03 08:45:56] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 08:46:04] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-03 08:46:06] [valid] Ep. 1 : Up. 750000 : perplexity : 4.30249 : new best
[2022-03-03 12:18:44] Ep. 1 : Up. 760000 : Sen. 118,905,778 : Cost 2.36219907 : Time 12774.86s : 16076.40 words/s : gNorm 0.6122
[2022-03-03 12:18:44] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 12:18:52] Saving Adam parameters
[2022-03-03 12:18:55] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 12:19:03] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-03 12:19:05] [valid] Ep. 1 : Up. 760000 : perplexity : 4.29874 : new best
[2022-03-03 15:52:12] Ep. 1 : Up. 770000 : Sen. 128,053,008 : Cost 2.36119151 : Time 12807.88s : 16043.86 words/s : gNorm 0.6200
[2022-03-03 15:52:12] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 15:52:15] Saving Adam parameters
[2022-03-03 15:52:19] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 15:52:27] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-03 15:52:29] [valid] Ep. 1 : Up. 770000 : perplexity : 4.29299 : new best
[2022-03-03 19:24:59] Ep. 1 : Up. 780000 : Sen. 137,193,522 : Cost 2.36015868 : Time 12766.98s : 16086.42 words/s : gNorm 0.5949
[2022-03-03 19:24:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 19:25:02] Saving Adam parameters
[2022-03-03 19:25:06] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 19:25:14] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-03 19:25:16] [valid] Ep. 1 : Up. 780000 : perplexity : 4.28831 : new best
[2022-03-03 22:57:52] Ep. 1 : Up. 790000 : Sen. 146,351,606 : Cost 2.36092257 : Time 12772.75s : 16081.30 words/s : gNorm 0.6733
[2022-03-03 22:57:52] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-03 22:57:55] Saving Adam parameters
[2022-03-03 22:57:58] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-03 22:58:06] [valid] Ep. 1 : Up. 790000 : perplexity : 4.28893 : stalled 1 times (last best: 4.28831)
[2022-03-04 02:30:46] Ep. 1 : Up. 800000 : Sen. 155,474,105 : Cost 2.35936499 : Time 12774.04s : 16072.12 words/s : gNorm 0.6156
[2022-03-04 02:30:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-04 02:30:49] Saving Adam parameters
[2022-03-04 02:30:53] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-04 02:31:00] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-04 02:31:03] [valid] Ep. 1 : Up. 800000 : perplexity : 4.28407 : new best
[2022-03-04 06:03:56] Ep. 1 : Up. 810000 : Sen. 164,619,953 : Cost 2.35822225 : Time 12790.51s : 16065.28 words/s : gNorm 0.5849
[2022-03-04 06:03:57] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-04 06:04:00] Saving Adam parameters
[2022-03-04 06:04:03] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-04 06:04:22] [valid] Ep. 1 : Up. 810000 : perplexity : 4.28713 : stalled 1 times (last best: 4.28407)
[2022-03-04 09:37:07] Ep. 1 : Up. 820000 : Sen. 173,759,503 : Cost 2.35822296 : Time 12790.13s : 16069.45 words/s : gNorm 0.6312
[2022-03-04 09:37:07] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-04 09:37:10] Saving Adam parameters
[2022-03-04 09:37:13] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-04 09:37:22] [valid] Ep. 1 : Up. 820000 : perplexity : 4.2858 : stalled 2 times (last best: 4.28407)
[2022-03-04 13:09:59] Ep. 1 : Up. 830000 : Sen. 182,912,066 : Cost 2.35879230 : Time 12772.15s : 16081.76 words/s : gNorm 0.6454
[2022-03-04 13:09:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-04 13:10:02] Saving Adam parameters
[2022-03-04 13:10:06] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-04 13:10:14] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-04 13:10:16] [valid] Ep. 1 : Up. 830000 : perplexity : 4.28376 : new best
[2022-03-05 22:11:04] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-05 22:11:04] [marian] Running on r15g03.bullx as process 27058 with command line:
[2022-03-05 22:11:04] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10818969/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-03-05 22:11:06] [config] after: 0e
[2022-03-05 22:11:06] [config] after-batches: 0
[2022-03-05 22:11:06] [config] after-epochs: 0
[2022-03-05 22:11:06] [config] all-caps-every: 0
[2022-03-05 22:11:06] [config] allow-unk: true
[2022-03-05 22:11:06] [config] authors: false
[2022-03-05 22:11:06] [config] beam-size: 6
[2022-03-05 22:11:06] [config] bert-class-symbol: "[CLS]"
[2022-03-05 22:11:06] [config] bert-mask-symbol: "[MASK]"
[2022-03-05 22:11:06] [config] bert-masking-fraction: 0.15
[2022-03-05 22:11:06] [config] bert-sep-symbol: "[SEP]"
[2022-03-05 22:11:06] [config] bert-train-type-embeddings: true
[2022-03-05 22:11:06] [config] bert-type-vocab-size: 2
[2022-03-05 22:11:06] [config] build-info: ""
[2022-03-05 22:11:06] [config] check-gradient-nan: false
[2022-03-05 22:11:06] [config] check-nan: false
[2022-03-05 22:11:06] [config] cite: false
[2022-03-05 22:11:06] [config] clip-norm: 0
[2022-03-05 22:11:06] [config] cost-scaling:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] cost-type: ce-mean-words
[2022-03-05 22:11:06] [config] cpu-threads: 0
[2022-03-05 22:11:06] [config] data-weighting: ""
[2022-03-05 22:11:06] [config] data-weighting-type: sentence
[2022-03-05 22:11:06] [config] dec-cell: gru
[2022-03-05 22:11:06] [config] dec-cell-base-depth: 2
[2022-03-05 22:11:06] [config] dec-cell-high-depth: 1
[2022-03-05 22:11:06] [config] dec-depth: 6
[2022-03-05 22:11:06] [config] devices:
[2022-03-05 22:11:06] [config]   - 0
[2022-03-05 22:11:06] [config]   - 1
[2022-03-05 22:11:06] [config] dim-emb: 1024
[2022-03-05 22:11:06] [config] dim-rnn: 1024
[2022-03-05 22:11:06] [config] dim-vocabs:
[2022-03-05 22:11:06] [config]   - 54728
[2022-03-05 22:11:06] [config]   - 54728
[2022-03-05 22:11:06] [config] disp-first: 0
[2022-03-05 22:11:06] [config] disp-freq: 10000
[2022-03-05 22:11:06] [config] disp-label-counts: true
[2022-03-05 22:11:06] [config] dropout-rnn: 0
[2022-03-05 22:11:06] [config] dropout-src: 0
[2022-03-05 22:11:06] [config] dropout-trg: 0
[2022-03-05 22:11:06] [config] dump-config: ""
[2022-03-05 22:11:06] [config] dynamic-gradient-scaling:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] early-stopping: 10
[2022-03-05 22:11:06] [config] early-stopping-on: first
[2022-03-05 22:11:06] [config] embedding-fix-src: false
[2022-03-05 22:11:06] [config] embedding-fix-trg: false
[2022-03-05 22:11:06] [config] embedding-normalization: false
[2022-03-05 22:11:06] [config] embedding-vectors:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] enc-cell: gru
[2022-03-05 22:11:06] [config] enc-cell-depth: 1
[2022-03-05 22:11:06] [config] enc-depth: 6
[2022-03-05 22:11:06] [config] enc-type: bidirectional
[2022-03-05 22:11:06] [config] english-title-case-every: 0
[2022-03-05 22:11:06] [config] exponential-smoothing: 0.0001
[2022-03-05 22:11:06] [config] factor-weight: 1
[2022-03-05 22:11:06] [config] factors-combine: sum
[2022-03-05 22:11:06] [config] factors-dim-emb: 0
[2022-03-05 22:11:06] [config] gradient-checkpointing: false
[2022-03-05 22:11:06] [config] gradient-norm-average-window: 100
[2022-03-05 22:11:06] [config] guided-alignment: none
[2022-03-05 22:11:06] [config] guided-alignment-cost: mse
[2022-03-05 22:11:06] [config] guided-alignment-weight: 0.1
[2022-03-05 22:11:06] [config] ignore-model-config: false
[2022-03-05 22:11:06] [config] input-types:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] interpolate-env-vars: false
[2022-03-05 22:11:06] [config] keep-best: true
[2022-03-05 22:11:06] [config] label-smoothing: 0.1
[2022-03-05 22:11:06] [config] layer-normalization: false
[2022-03-05 22:11:06] [config] learn-rate: 0.0002
[2022-03-05 22:11:06] [config] lemma-dependency: ""
[2022-03-05 22:11:06] [config] lemma-dim-emb: 0
[2022-03-05 22:11:06] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-03-05 22:11:06] [config] log-level: info
[2022-03-05 22:11:06] [config] log-time-zone: ""
[2022-03-05 22:11:06] [config] logical-epoch:
[2022-03-05 22:11:06] [config]   - 1e
[2022-03-05 22:11:06] [config]   - 0
[2022-03-05 22:11:06] [config] lr-decay: 0
[2022-03-05 22:11:06] [config] lr-decay-freq: 50000
[2022-03-05 22:11:06] [config] lr-decay-inv-sqrt:
[2022-03-05 22:11:06] [config]   - 8000
[2022-03-05 22:11:06] [config] lr-decay-repeat-warmup: false
[2022-03-05 22:11:06] [config] lr-decay-reset-optimizer: false
[2022-03-05 22:11:06] [config] lr-decay-start:
[2022-03-05 22:11:06] [config]   - 10
[2022-03-05 22:11:06] [config]   - 1
[2022-03-05 22:11:06] [config] lr-decay-strategy: epoch+stalled
[2022-03-05 22:11:06] [config] lr-report: false
[2022-03-05 22:11:06] [config] lr-warmup: 8000
[2022-03-05 22:11:06] [config] lr-warmup-at-reload: false
[2022-03-05 22:11:06] [config] lr-warmup-cycle: false
[2022-03-05 22:11:06] [config] lr-warmup-start-rate: 0
[2022-03-05 22:11:06] [config] max-length: 100
[2022-03-05 22:11:06] [config] max-length-crop: false
[2022-03-05 22:11:06] [config] max-length-factor: 3
[2022-03-05 22:11:06] [config] maxi-batch: 1000
[2022-03-05 22:11:06] [config] maxi-batch-sort: trg
[2022-03-05 22:11:06] [config] mini-batch: 1000
[2022-03-05 22:11:06] [config] mini-batch-fit: true
[2022-03-05 22:11:06] [config] mini-batch-fit-step: 10
[2022-03-05 22:11:06] [config] mini-batch-round-up: true
[2022-03-05 22:11:06] [config] mini-batch-track-lr: false
[2022-03-05 22:11:06] [config] mini-batch-warmup: 0
[2022-03-05 22:11:06] [config] mini-batch-words: 0
[2022-03-05 22:11:06] [config] mini-batch-words-ref: 0
[2022-03-05 22:11:06] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-05 22:11:06] [config] multi-loss-type: sum
[2022-03-05 22:11:06] [config] n-best: false
[2022-03-05 22:11:06] [config] no-nccl: false
[2022-03-05 22:11:06] [config] no-reload: false
[2022-03-05 22:11:06] [config] no-restore-corpus: true
[2022-03-05 22:11:06] [config] normalize: 1
[2022-03-05 22:11:06] [config] normalize-gradient: false
[2022-03-05 22:11:06] [config] num-devices: 0
[2022-03-05 22:11:06] [config] optimizer: adam
[2022-03-05 22:11:06] [config] optimizer-delay: 2
[2022-03-05 22:11:06] [config] optimizer-params:
[2022-03-05 22:11:06] [config]   - 0.9
[2022-03-05 22:11:06] [config]   - 0.998
[2022-03-05 22:11:06] [config]   - 1e-09
[2022-03-05 22:11:06] [config] output-omit-bias: false
[2022-03-05 22:11:06] [config] overwrite: true
[2022-03-05 22:11:06] [config] precision:
[2022-03-05 22:11:06] [config]   - float32
[2022-03-05 22:11:06] [config]   - float32
[2022-03-05 22:11:06] [config] pretrained-model: ""
[2022-03-05 22:11:06] [config] quantize-biases: false
[2022-03-05 22:11:06] [config] quantize-bits: 0
[2022-03-05 22:11:06] [config] quantize-log-based: false
[2022-03-05 22:11:06] [config] quantize-optimization-steps: 0
[2022-03-05 22:11:06] [config] quiet: false
[2022-03-05 22:11:06] [config] quiet-translation: false
[2022-03-05 22:11:06] [config] relative-paths: false
[2022-03-05 22:11:06] [config] right-left: false
[2022-03-05 22:11:06] [config] save-freq: 10000
[2022-03-05 22:11:06] [config] seed: 1111
[2022-03-05 22:11:06] [config] sentencepiece-alphas:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] sentencepiece-max-lines: 2000000
[2022-03-05 22:11:06] [config] sentencepiece-options: ""
[2022-03-05 22:11:06] [config] sharding: local
[2022-03-05 22:11:06] [config] shuffle: batches
[2022-03-05 22:11:06] [config] shuffle-in-ram: false
[2022-03-05 22:11:06] [config] sigterm: save-and-exit
[2022-03-05 22:11:06] [config] skip: false
[2022-03-05 22:11:06] [config] sqlite: ""
[2022-03-05 22:11:06] [config] sqlite-drop: false
[2022-03-05 22:11:06] [config] sync-freq: 200u
[2022-03-05 22:11:06] [config] sync-sgd: true
[2022-03-05 22:11:06] [config] tempdir: /run/nvme/job_10818969/tmp
[2022-03-05 22:11:06] [config] tied-embeddings: false
[2022-03-05 22:11:06] [config] tied-embeddings-all: true
[2022-03-05 22:11:06] [config] tied-embeddings-src: false
[2022-03-05 22:11:06] [config] train-embedder-rank:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] train-sets:
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-03-05 22:11:06] [config] transformer-aan-activation: swish
[2022-03-05 22:11:06] [config] transformer-aan-depth: 2
[2022-03-05 22:11:06] [config] transformer-aan-nogate: false
[2022-03-05 22:11:06] [config] transformer-decoder-autoreg: self-attention
[2022-03-05 22:11:06] [config] transformer-depth-scaling: false
[2022-03-05 22:11:06] [config] transformer-dim-aan: 2048
[2022-03-05 22:11:06] [config] transformer-dim-ffn: 4096
[2022-03-05 22:11:06] [config] transformer-dropout: 0.1
[2022-03-05 22:11:06] [config] transformer-dropout-attention: 0
[2022-03-05 22:11:06] [config] transformer-dropout-ffn: 0
[2022-03-05 22:11:06] [config] transformer-ffn-activation: relu
[2022-03-05 22:11:06] [config] transformer-ffn-depth: 2
[2022-03-05 22:11:06] [config] transformer-guided-alignment-layer: last
[2022-03-05 22:11:06] [config] transformer-heads: 16
[2022-03-05 22:11:06] [config] transformer-no-projection: false
[2022-03-05 22:11:06] [config] transformer-pool: false
[2022-03-05 22:11:06] [config] transformer-postprocess: dan
[2022-03-05 22:11:06] [config] transformer-postprocess-emb: d
[2022-03-05 22:11:06] [config] transformer-postprocess-top: ""
[2022-03-05 22:11:06] [config] transformer-preprocess: ""
[2022-03-05 22:11:06] [config] transformer-tied-layers:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] transformer-train-position-embeddings: false
[2022-03-05 22:11:06] [config] tsv: false
[2022-03-05 22:11:06] [config] tsv-fields: 0
[2022-03-05 22:11:06] [config] type: transformer
[2022-03-05 22:11:06] [config] ulr: false
[2022-03-05 22:11:06] [config] ulr-dim-emb: 0
[2022-03-05 22:11:06] [config] ulr-dropout: 0
[2022-03-05 22:11:06] [config] ulr-keys-vectors: ""
[2022-03-05 22:11:06] [config] ulr-query-vectors: ""
[2022-03-05 22:11:06] [config] ulr-softmax-temperature: 1
[2022-03-05 22:11:06] [config] ulr-trainable-transformation: false
[2022-03-05 22:11:06] [config] unlikelihood-loss: false
[2022-03-05 22:11:06] [config] valid-freq: 10000
[2022-03-05 22:11:06] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-03-05 22:11:06] [config] valid-max-length: 100
[2022-03-05 22:11:06] [config] valid-metrics:
[2022-03-05 22:11:06] [config]   - perplexity
[2022-03-05 22:11:06] [config] valid-mini-batch: 16
[2022-03-05 22:11:06] [config] valid-reset-stalled: false
[2022-03-05 22:11:06] [config] valid-script-args:
[2022-03-05 22:11:06] [config]   []
[2022-03-05 22:11:06] [config] valid-script-path: ""
[2022-03-05 22:11:06] [config] valid-sets:
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-03-05 22:11:06] [config] valid-translation-output: ""
[2022-03-05 22:11:06] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-05 22:11:06] [config] vocabs:
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-05 22:11:06] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-05 22:11:06] [config] word-penalty: 0
[2022-03-05 22:11:06] [config] word-scores: false
[2022-03-05 22:11:06] [config] workspace: 15000
[2022-03-05 22:11:06] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-05 22:11:06] Using synchronous SGD
[2022-03-05 22:11:06] [comm] Compiled without MPI support. Running as a single process on r15g03.bullx
[2022-03-05 22:11:06] Synced seed 1111
[2022-03-05 22:11:06] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-05 22:11:06] [data] Setting vocabulary size for input 0 to 54,728
[2022-03-05 22:11:06] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-05 22:11:07] [data] Setting vocabulary size for input 1 to 54,728
[2022-03-05 22:11:07] [batching] Collecting statistics for batch fitting with step size 10
[2022-03-05 22:11:08] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-05 22:11:09] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-05 22:11:09] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-05 22:11:09] [comm] Using global sharding
[2022-03-05 22:11:10] [comm] NCCLCommunicators constructed successfully
[2022-03-05 22:11:10] [training] Using 2 GPUs
[2022-03-05 22:11:10] [logits] Applying loss function for 1 factor(s)
[2022-03-05 22:11:10] [memory] Reserving 886 MB, device gpu0
[2022-03-05 22:11:11] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-03-05 22:11:11] [memory] Reserving 886 MB, device gpu0
[2022-03-05 22:11:35] [batching] Done. Typical MB size is 27,536 target words
[2022-03-05 22:11:35] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-05 22:11:35] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-05 22:11:35] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-05 22:11:35] [comm] Using global sharding
[2022-03-05 22:11:35] [comm] NCCLCommunicators constructed successfully
[2022-03-05 22:11:35] [training] Using 2 GPUs
[2022-03-05 22:11:35] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-05 22:11:38] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-05 22:11:47] Allocating memory for general optimizer shards
[2022-03-05 22:11:47] [memory] Reserving 443 MB, device gpu0
[2022-03-05 22:11:47] [memory] Reserving 443 MB, device gpu1
[2022-03-05 22:11:47] Loading Adam parameters
[2022-03-05 22:11:48] [memory] Reserving 886 MB, device gpu0
[2022-03-05 22:11:48] [memory] Reserving 886 MB, device gpu1
[2022-03-05 22:11:48] [memory] Reserving 886 MB, device gpu0
[2022-03-05 22:11:49] [memory] Reserving 886 MB, device gpu1
[2022-03-05 22:11:49] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-05 22:11:49] Training started
[2022-03-05 22:12:14] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-03-05 22:12:15] [memory] Reserving 886 MB, device gpu0
[2022-03-05 22:12:15] [memory] Reserving 886 MB, device gpu1
[2022-03-05 22:12:17] Parameter type float32, optimization type float32, casting types false
[2022-03-06 01:46:22] Ep. 1 : Up. 840000 : Sen. 9,157,155 : Cost 2.35648632 : Time 12887.44s : 15936.87 words/s : gNorm 0.6799
[2022-03-06 01:46:22] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 01:46:25] Saving Adam parameters
[2022-03-06 01:46:29] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 01:46:37] [valid] Ep. 1 : Up. 840000 : perplexity : 4.28499 : stalled 3 times (last best: 4.28407)
[2022-03-06 05:20:05] Ep. 1 : Up. 850000 : Sen. 18,299,011 : Cost 2.35489035 : Time 12822.80s : 16031.93 words/s : gNorm 0.6216
[2022-03-06 05:20:05] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 05:20:08] Saving Adam parameters
[2022-03-06 05:20:12] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 05:20:20] [valid] Ep. 1 : Up. 850000 : perplexity : 4.28859 : stalled 4 times (last best: 4.28407)
[2022-03-06 08:53:33] Ep. 1 : Up. 860000 : Sen. 27,429,933 : Cost 2.35432601 : Time 12807.86s : 16039.19 words/s : gNorm 0.5751
[2022-03-06 08:53:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 08:53:37] Saving Adam parameters
[2022-03-06 08:53:40] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 08:53:48] [valid] Ep. 1 : Up. 860000 : perplexity : 4.28801 : stalled 5 times (last best: 4.28407)
[2022-03-06 12:27:01] Ep. 1 : Up. 870000 : Sen. 36,599,477 : Cost 2.35430551 : Time 12808.54s : 16043.68 words/s : gNorm 0.6136
[2022-03-06 12:27:01] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 12:27:05] Saving Adam parameters
[2022-03-06 12:27:08] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 12:27:16] [valid] Ep. 1 : Up. 870000 : perplexity : 4.28636 : stalled 6 times (last best: 4.28407)
[2022-03-06 16:00:33] Ep. 1 : Up. 880000 : Sen. 45,732,248 : Cost 2.35408115 : Time 12811.98s : 16023.40 words/s : gNorm 0.6008
[2022-03-06 16:00:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 16:00:38] Saving Adam parameters
[2022-03-06 16:00:42] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 16:00:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-06 16:00:52] [valid] Ep. 1 : Up. 880000 : perplexity : 4.28396 : new best
[2022-03-06 19:34:13] Ep. 1 : Up. 890000 : Sen. 54,887,710 : Cost 2.35338950 : Time 12819.28s : 16024.73 words/s : gNorm 0.6281
[2022-03-06 19:34:13] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 19:34:16] Saving Adam parameters
[2022-03-06 19:34:20] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 19:34:28] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-06 19:34:32] [valid] Ep. 1 : Up. 890000 : perplexity : 4.28066 : new best
[2022-03-06 23:08:04] Ep. 1 : Up. 900000 : Sen. 64,018,771 : Cost 2.35213017 : Time 12831.14s : 16009.09 words/s : gNorm 0.6536
[2022-03-06 23:08:04] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-06 23:08:10] Saving Adam parameters
[2022-03-06 23:08:17] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-06 23:08:28] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-06 23:08:31] [valid] Ep. 1 : Up. 900000 : perplexity : 4.27636 : new best
[2022-03-07 02:41:57] Ep. 1 : Up. 910000 : Sen. 73,175,796 : Cost 2.35232949 : Time 12832.90s : 16016.52 words/s : gNorm 0.6025
[2022-03-07 02:41:57] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 02:42:01] Saving Adam parameters
[2022-03-07 02:42:05] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 02:42:13] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-07 02:42:15] [valid] Ep. 1 : Up. 910000 : perplexity : 4.27444 : new best
[2022-03-07 06:15:35] Ep. 1 : Up. 920000 : Sen. 82,321,838 : Cost 2.35148025 : Time 12818.19s : 16024.46 words/s : gNorm 0.6171
[2022-03-07 06:15:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 06:15:39] Saving Adam parameters
[2022-03-07 06:15:43] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 06:15:59] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-07 06:16:01] [valid] Ep. 1 : Up. 920000 : perplexity : 4.27061 : new best
[2022-03-07 09:49:29] Ep. 1 : Up. 930000 : Sen. 91,465,281 : Cost 2.35164189 : Time 12833.82s : 16006.29 words/s : gNorm 0.6850
[2022-03-07 09:49:29] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 09:49:33] Saving Adam parameters
[2022-03-07 09:49:36] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 09:49:44] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-07 09:49:47] [valid] Ep. 1 : Up. 930000 : perplexity : 4.2654 : new best
[2022-03-07 13:23:18] Ep. 1 : Up. 940000 : Sen. 100,615,039 : Cost 2.35068440 : Time 12829.50s : 16019.24 words/s : gNorm 0.6288
[2022-03-07 13:23:19] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 13:23:22] Saving Adam parameters
[2022-03-07 13:23:25] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 13:23:34] [valid] Ep. 1 : Up. 940000 : perplexity : 4.26694 : stalled 1 times (last best: 4.2654)
[2022-03-07 16:57:01] Ep. 1 : Up. 950000 : Sen. 109,738,459 : Cost 2.34967375 : Time 12822.06s : 16024.70 words/s : gNorm 0.6975
[2022-03-07 16:57:01] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 16:57:07] Saving Adam parameters
[2022-03-07 16:57:10] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 16:57:28] [valid] Ep. 1 : Up. 950000 : perplexity : 4.26668 : stalled 2 times (last best: 4.2654)
[2022-03-07 20:30:51] Ep. 1 : Up. 960000 : Sen. 118,905,778 : Cost 2.35068083 : Time 12830.70s : 16006.44 words/s : gNorm 0.6416
[2022-03-07 20:30:51] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-07 20:30:55] Saving Adam parameters
[2022-03-07 20:30:58] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-07 20:31:06] [valid] Ep. 1 : Up. 960000 : perplexity : 4.2665 : stalled 3 times (last best: 4.2654)
[2022-03-08 00:05:03] Ep. 1 : Up. 970000 : Sen. 128,053,008 : Cost 2.34984040 : Time 12851.77s : 15989.08 words/s : gNorm 0.6515
[2022-03-08 00:05:03] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 00:05:06] Saving Adam parameters
[2022-03-08 00:05:10] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 00:05:18] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-08 00:05:21] [valid] Ep. 1 : Up. 970000 : perplexity : 4.26087 : new best
[2022-03-08 03:38:38] Ep. 1 : Up. 980000 : Sen. 137,193,522 : Cost 2.34898591 : Time 12814.50s : 16026.77 words/s : gNorm 0.6193
[2022-03-08 03:38:38] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 03:38:42] Saving Adam parameters
[2022-03-08 03:38:46] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 03:38:54] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-08 03:38:56] [valid] Ep. 1 : Up. 980000 : perplexity : 4.25673 : new best
[2022-03-08 07:12:26] Ep. 1 : Up. 990000 : Sen. 146,351,606 : Cost 2.34987664 : Time 12828.05s : 16011.98 words/s : gNorm 0.7078
[2022-03-08 07:12:26] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 07:12:29] Saving Adam parameters
[2022-03-08 07:12:33] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 07:12:47] [valid] Ep. 1 : Up. 990000 : perplexity : 4.25719 : stalled 1 times (last best: 4.25673)
[2022-03-08 10:46:15] Ep. 1 : Up. 1000000 : Sen. 155,474,105 : Cost 2.34846950 : Time 12828.86s : 16003.45 words/s : gNorm 0.6462
[2022-03-08 10:46:15] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 10:46:18] Saving Adam parameters
[2022-03-08 10:46:22] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 10:46:52] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-08 10:46:54] [valid] Ep. 1 : Up. 1000000 : perplexity : 4.25355 : new best
[2022-03-08 14:20:33] Ep. 1 : Up. 1010000 : Sen. 164,619,953 : Cost 2.34752369 : Time 12857.91s : 15981.06 words/s : gNorm 0.6087
[2022-03-08 14:20:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 14:20:43] Saving Adam parameters
[2022-03-08 14:20:47] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 14:20:55] [valid] Ep. 1 : Up. 1010000 : perplexity : 4.25729 : stalled 1 times (last best: 4.25355)
[2022-03-08 17:54:33] Ep. 1 : Up. 1020000 : Sen. 173,759,503 : Cost 2.34764075 : Time 12840.03s : 16007.01 words/s : gNorm 0.6591
[2022-03-08 17:54:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 17:54:37] Saving Adam parameters
[2022-03-08 17:54:40] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 17:54:48] [valid] Ep. 1 : Up. 1020000 : perplexity : 4.25713 : stalled 2 times (last best: 4.25355)
[2022-03-08 21:28:29] Ep. 1 : Up. 1030000 : Sen. 182,912,066 : Cost 2.34836793 : Time 12835.73s : 16002.10 words/s : gNorm 0.6735
[2022-03-08 21:28:29] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 21:28:32] Saving Adam parameters
[2022-03-08 21:28:36] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 21:28:44] [valid] Ep. 1 : Up. 1030000 : perplexity : 4.25673 : stalled 3 times (last best: 4.25355)
[2022-03-08 22:23:56] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-08 22:23:56] [marian] Running on r13g04.bullx as process 132827 with command line:
[2022-03-08 22:23:56] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10875317/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-03-08 22:23:59] [config] after: 0e
[2022-03-08 22:23:59] [config] after-batches: 0
[2022-03-08 22:23:59] [config] after-epochs: 0
[2022-03-08 22:23:59] [config] all-caps-every: 0
[2022-03-08 22:23:59] [config] allow-unk: true
[2022-03-08 22:23:59] [config] authors: false
[2022-03-08 22:23:59] [config] beam-size: 6
[2022-03-08 22:23:59] [config] bert-class-symbol: "[CLS]"
[2022-03-08 22:23:59] [config] bert-mask-symbol: "[MASK]"
[2022-03-08 22:23:59] [config] bert-masking-fraction: 0.15
[2022-03-08 22:23:59] [config] bert-sep-symbol: "[SEP]"
[2022-03-08 22:23:59] [config] bert-train-type-embeddings: true
[2022-03-08 22:23:59] [config] bert-type-vocab-size: 2
[2022-03-08 22:23:59] [config] build-info: ""
[2022-03-08 22:23:59] [config] check-gradient-nan: false
[2022-03-08 22:23:59] [config] check-nan: false
[2022-03-08 22:23:59] [config] cite: false
[2022-03-08 22:23:59] [config] clip-norm: 0
[2022-03-08 22:23:59] [config] cost-scaling:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] cost-type: ce-mean-words
[2022-03-08 22:23:59] [config] cpu-threads: 0
[2022-03-08 22:23:59] [config] data-weighting: ""
[2022-03-08 22:23:59] [config] data-weighting-type: sentence
[2022-03-08 22:23:59] [config] dec-cell: gru
[2022-03-08 22:23:59] [config] dec-cell-base-depth: 2
[2022-03-08 22:23:59] [config] dec-cell-high-depth: 1
[2022-03-08 22:23:59] [config] dec-depth: 6
[2022-03-08 22:23:59] [config] devices:
[2022-03-08 22:23:59] [config]   - 0
[2022-03-08 22:23:59] [config]   - 1
[2022-03-08 22:23:59] [config] dim-emb: 1024
[2022-03-08 22:23:59] [config] dim-rnn: 1024
[2022-03-08 22:23:59] [config] dim-vocabs:
[2022-03-08 22:23:59] [config]   - 54728
[2022-03-08 22:23:59] [config]   - 54728
[2022-03-08 22:23:59] [config] disp-first: 0
[2022-03-08 22:23:59] [config] disp-freq: 10000
[2022-03-08 22:23:59] [config] disp-label-counts: true
[2022-03-08 22:23:59] [config] dropout-rnn: 0
[2022-03-08 22:23:59] [config] dropout-src: 0
[2022-03-08 22:23:59] [config] dropout-trg: 0
[2022-03-08 22:23:59] [config] dump-config: ""
[2022-03-08 22:23:59] [config] dynamic-gradient-scaling:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] early-stopping: 10
[2022-03-08 22:23:59] [config] early-stopping-on: first
[2022-03-08 22:23:59] [config] embedding-fix-src: false
[2022-03-08 22:23:59] [config] embedding-fix-trg: false
[2022-03-08 22:23:59] [config] embedding-normalization: false
[2022-03-08 22:23:59] [config] embedding-vectors:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] enc-cell: gru
[2022-03-08 22:23:59] [config] enc-cell-depth: 1
[2022-03-08 22:23:59] [config] enc-depth: 6
[2022-03-08 22:23:59] [config] enc-type: bidirectional
[2022-03-08 22:23:59] [config] english-title-case-every: 0
[2022-03-08 22:23:59] [config] exponential-smoothing: 0.0001
[2022-03-08 22:23:59] [config] factor-weight: 1
[2022-03-08 22:23:59] [config] factors-combine: sum
[2022-03-08 22:23:59] [config] factors-dim-emb: 0
[2022-03-08 22:23:59] [config] gradient-checkpointing: false
[2022-03-08 22:23:59] [config] gradient-norm-average-window: 100
[2022-03-08 22:23:59] [config] guided-alignment: none
[2022-03-08 22:23:59] [config] guided-alignment-cost: mse
[2022-03-08 22:23:59] [config] guided-alignment-weight: 0.1
[2022-03-08 22:23:59] [config] ignore-model-config: false
[2022-03-08 22:23:59] [config] input-types:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] interpolate-env-vars: false
[2022-03-08 22:23:59] [config] keep-best: true
[2022-03-08 22:23:59] [config] label-smoothing: 0.1
[2022-03-08 22:23:59] [config] layer-normalization: false
[2022-03-08 22:23:59] [config] learn-rate: 0.0002
[2022-03-08 22:23:59] [config] lemma-dependency: ""
[2022-03-08 22:23:59] [config] lemma-dim-emb: 0
[2022-03-08 22:23:59] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-03-08 22:23:59] [config] log-level: info
[2022-03-08 22:23:59] [config] log-time-zone: ""
[2022-03-08 22:23:59] [config] logical-epoch:
[2022-03-08 22:23:59] [config]   - 1e
[2022-03-08 22:23:59] [config]   - 0
[2022-03-08 22:23:59] [config] lr-decay: 0
[2022-03-08 22:23:59] [config] lr-decay-freq: 50000
[2022-03-08 22:23:59] [config] lr-decay-inv-sqrt:
[2022-03-08 22:23:59] [config]   - 8000
[2022-03-08 22:23:59] [config] lr-decay-repeat-warmup: false
[2022-03-08 22:23:59] [config] lr-decay-reset-optimizer: false
[2022-03-08 22:23:59] [config] lr-decay-start:
[2022-03-08 22:23:59] [config]   - 10
[2022-03-08 22:23:59] [config]   - 1
[2022-03-08 22:23:59] [config] lr-decay-strategy: epoch+stalled
[2022-03-08 22:23:59] [config] lr-report: false
[2022-03-08 22:23:59] [config] lr-warmup: 8000
[2022-03-08 22:23:59] [config] lr-warmup-at-reload: false
[2022-03-08 22:23:59] [config] lr-warmup-cycle: false
[2022-03-08 22:23:59] [config] lr-warmup-start-rate: 0
[2022-03-08 22:23:59] [config] max-length: 100
[2022-03-08 22:23:59] [config] max-length-crop: false
[2022-03-08 22:23:59] [config] max-length-factor: 3
[2022-03-08 22:23:59] [config] maxi-batch: 1000
[2022-03-08 22:23:59] [config] maxi-batch-sort: trg
[2022-03-08 22:23:59] [config] mini-batch: 1000
[2022-03-08 22:23:59] [config] mini-batch-fit: true
[2022-03-08 22:23:59] [config] mini-batch-fit-step: 10
[2022-03-08 22:23:59] [config] mini-batch-round-up: true
[2022-03-08 22:23:59] [config] mini-batch-track-lr: false
[2022-03-08 22:23:59] [config] mini-batch-warmup: 0
[2022-03-08 22:23:59] [config] mini-batch-words: 0
[2022-03-08 22:23:59] [config] mini-batch-words-ref: 0
[2022-03-08 22:23:59] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 22:23:59] [config] multi-loss-type: sum
[2022-03-08 22:23:59] [config] n-best: false
[2022-03-08 22:23:59] [config] no-nccl: false
[2022-03-08 22:23:59] [config] no-reload: false
[2022-03-08 22:23:59] [config] no-restore-corpus: true
[2022-03-08 22:23:59] [config] normalize: 1
[2022-03-08 22:23:59] [config] normalize-gradient: false
[2022-03-08 22:23:59] [config] num-devices: 0
[2022-03-08 22:23:59] [config] optimizer: adam
[2022-03-08 22:23:59] [config] optimizer-delay: 2
[2022-03-08 22:23:59] [config] optimizer-params:
[2022-03-08 22:23:59] [config]   - 0.9
[2022-03-08 22:23:59] [config]   - 0.998
[2022-03-08 22:23:59] [config]   - 1e-09
[2022-03-08 22:23:59] [config] output-omit-bias: false
[2022-03-08 22:23:59] [config] overwrite: true
[2022-03-08 22:23:59] [config] precision:
[2022-03-08 22:23:59] [config]   - float32
[2022-03-08 22:23:59] [config]   - float32
[2022-03-08 22:23:59] [config] pretrained-model: ""
[2022-03-08 22:23:59] [config] quantize-biases: false
[2022-03-08 22:23:59] [config] quantize-bits: 0
[2022-03-08 22:23:59] [config] quantize-log-based: false
[2022-03-08 22:23:59] [config] quantize-optimization-steps: 0
[2022-03-08 22:23:59] [config] quiet: false
[2022-03-08 22:23:59] [config] quiet-translation: false
[2022-03-08 22:23:59] [config] relative-paths: false
[2022-03-08 22:23:59] [config] right-left: false
[2022-03-08 22:23:59] [config] save-freq: 10000
[2022-03-08 22:23:59] [config] seed: 1111
[2022-03-08 22:23:59] [config] sentencepiece-alphas:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] sentencepiece-max-lines: 2000000
[2022-03-08 22:23:59] [config] sentencepiece-options: ""
[2022-03-08 22:23:59] [config] sharding: local
[2022-03-08 22:23:59] [config] shuffle: batches
[2022-03-08 22:23:59] [config] shuffle-in-ram: false
[2022-03-08 22:23:59] [config] sigterm: save-and-exit
[2022-03-08 22:23:59] [config] skip: false
[2022-03-08 22:23:59] [config] sqlite: ""
[2022-03-08 22:23:59] [config] sqlite-drop: false
[2022-03-08 22:23:59] [config] sync-freq: 200u
[2022-03-08 22:23:59] [config] sync-sgd: true
[2022-03-08 22:23:59] [config] tempdir: /run/nvme/job_10875317/tmp
[2022-03-08 22:23:59] [config] tied-embeddings: false
[2022-03-08 22:23:59] [config] tied-embeddings-all: true
[2022-03-08 22:23:59] [config] tied-embeddings-src: false
[2022-03-08 22:23:59] [config] train-embedder-rank:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] train-sets:
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-03-08 22:23:59] [config] transformer-aan-activation: swish
[2022-03-08 22:23:59] [config] transformer-aan-depth: 2
[2022-03-08 22:23:59] [config] transformer-aan-nogate: false
[2022-03-08 22:23:59] [config] transformer-decoder-autoreg: self-attention
[2022-03-08 22:23:59] [config] transformer-depth-scaling: false
[2022-03-08 22:23:59] [config] transformer-dim-aan: 2048
[2022-03-08 22:23:59] [config] transformer-dim-ffn: 4096
[2022-03-08 22:23:59] [config] transformer-dropout: 0.1
[2022-03-08 22:23:59] [config] transformer-dropout-attention: 0
[2022-03-08 22:23:59] [config] transformer-dropout-ffn: 0
[2022-03-08 22:23:59] [config] transformer-ffn-activation: relu
[2022-03-08 22:23:59] [config] transformer-ffn-depth: 2
[2022-03-08 22:23:59] [config] transformer-guided-alignment-layer: last
[2022-03-08 22:23:59] [config] transformer-heads: 16
[2022-03-08 22:23:59] [config] transformer-no-projection: false
[2022-03-08 22:23:59] [config] transformer-pool: false
[2022-03-08 22:23:59] [config] transformer-postprocess: dan
[2022-03-08 22:23:59] [config] transformer-postprocess-emb: d
[2022-03-08 22:23:59] [config] transformer-postprocess-top: ""
[2022-03-08 22:23:59] [config] transformer-preprocess: ""
[2022-03-08 22:23:59] [config] transformer-tied-layers:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] transformer-train-position-embeddings: false
[2022-03-08 22:23:59] [config] tsv: false
[2022-03-08 22:23:59] [config] tsv-fields: 0
[2022-03-08 22:23:59] [config] type: transformer
[2022-03-08 22:23:59] [config] ulr: false
[2022-03-08 22:23:59] [config] ulr-dim-emb: 0
[2022-03-08 22:23:59] [config] ulr-dropout: 0
[2022-03-08 22:23:59] [config] ulr-keys-vectors: ""
[2022-03-08 22:23:59] [config] ulr-query-vectors: ""
[2022-03-08 22:23:59] [config] ulr-softmax-temperature: 1
[2022-03-08 22:23:59] [config] ulr-trainable-transformation: false
[2022-03-08 22:23:59] [config] unlikelihood-loss: false
[2022-03-08 22:23:59] [config] valid-freq: 10000
[2022-03-08 22:23:59] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-03-08 22:23:59] [config] valid-max-length: 100
[2022-03-08 22:23:59] [config] valid-metrics:
[2022-03-08 22:23:59] [config]   - perplexity
[2022-03-08 22:23:59] [config] valid-mini-batch: 16
[2022-03-08 22:23:59] [config] valid-reset-stalled: false
[2022-03-08 22:23:59] [config] valid-script-args:
[2022-03-08 22:23:59] [config]   []
[2022-03-08 22:23:59] [config] valid-script-path: ""
[2022-03-08 22:23:59] [config] valid-sets:
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-03-08 22:23:59] [config] valid-translation-output: ""
[2022-03-08 22:23:59] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-08 22:23:59] [config] vocabs:
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-08 22:23:59] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-08 22:23:59] [config] word-penalty: 0
[2022-03-08 22:23:59] [config] word-scores: false
[2022-03-08 22:23:59] [config] workspace: 15000
[2022-03-08 22:23:59] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-08 22:23:59] Using synchronous SGD
[2022-03-08 22:23:59] [comm] Compiled without MPI support. Running as a single process on r13g04.bullx
[2022-03-08 22:23:59] Synced seed 1111
[2022-03-08 22:23:59] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-08 22:23:59] [data] Setting vocabulary size for input 0 to 54,728
[2022-03-08 22:23:59] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-08 22:23:59] [data] Setting vocabulary size for input 1 to 54,728
[2022-03-08 22:24:00] [batching] Collecting statistics for batch fitting with step size 10
[2022-03-08 22:24:00] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-08 22:24:03] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-08 22:24:03] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-08 22:24:03] [comm] Using global sharding
[2022-03-08 22:24:04] [comm] NCCLCommunicators constructed successfully
[2022-03-08 22:24:04] [training] Using 2 GPUs
[2022-03-08 22:24:04] [logits] Applying loss function for 1 factor(s)
[2022-03-08 22:24:04] [memory] Reserving 886 MB, device gpu0
[2022-03-08 22:24:07] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-03-08 22:24:07] [memory] Reserving 886 MB, device gpu0
[2022-03-08 22:24:30] [batching] Done. Typical MB size is 27,536 target words
[2022-03-08 22:24:30] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-08 22:24:30] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-08 22:24:30] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-08 22:24:30] [comm] Using global sharding
[2022-03-08 22:24:30] [comm] NCCLCommunicators constructed successfully
[2022-03-08 22:24:30] [training] Using 2 GPUs
[2022-03-08 22:24:30] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 22:24:33] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-08 22:24:40] Allocating memory for general optimizer shards
[2022-03-08 22:24:40] [memory] Reserving 443 MB, device gpu0
[2022-03-08 22:24:40] [memory] Reserving 443 MB, device gpu1
[2022-03-08 22:24:41] Loading Adam parameters
[2022-03-08 22:24:41] [memory] Reserving 886 MB, device gpu0
[2022-03-08 22:24:41] [memory] Reserving 886 MB, device gpu1
[2022-03-08 22:24:42] [memory] Reserving 886 MB, device gpu0
[2022-03-08 22:24:42] [memory] Reserving 886 MB, device gpu1
[2022-03-08 22:24:42] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-08 22:24:42] Training started
[2022-03-08 22:25:05] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-03-08 22:25:05] [memory] Reserving 886 MB, device gpu0
[2022-03-08 22:25:06] [memory] Reserving 886 MB, device gpu1
[2022-03-08 22:25:08] Parameter type float32, optimization type float32, casting types false
[2022-03-09 01:58:26] Ep. 1 : Up. 1040000 : Sen. 9,157,155 : Cost 2.34637117 : Time 12836.24s : 16000.43 words/s : gNorm 0.7113
[2022-03-09 01:58:26] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 01:58:29] Saving Adam parameters
[2022-03-09 01:58:33] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 01:58:41] [valid] Ep. 1 : Up. 1040000 : perplexity : 4.25608 : stalled 3 times (last best: 4.25355)
[2022-03-09 05:31:46] Ep. 1 : Up. 1050000 : Sen. 18,299,011 : Cost 2.34494615 : Time 12800.10s : 16060.36 words/s : gNorm 0.6478
[2022-03-09 05:31:46] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 05:31:49] Saving Adam parameters
[2022-03-09 05:31:53] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 05:32:00] [valid] Ep. 1 : Up. 1050000 : perplexity : 4.25899 : stalled 4 times (last best: 4.25355)
[2022-03-09 09:04:47] Ep. 1 : Up. 1060000 : Sen. 27,429,933 : Cost 2.34453702 : Time 12780.53s : 16073.50 words/s : gNorm 0.5965
[2022-03-09 09:04:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 09:04:50] Saving Adam parameters
[2022-03-09 09:04:54] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 09:05:02] [valid] Ep. 1 : Up. 1060000 : perplexity : 4.26056 : stalled 5 times (last best: 4.25355)
[2022-03-09 12:37:46] Ep. 1 : Up. 1070000 : Sen. 36,599,477 : Cost 2.34466839 : Time 12779.60s : 16080.02 words/s : gNorm 0.6401
[2022-03-09 12:37:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 12:37:50] Saving Adam parameters
[2022-03-09 12:37:53] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 12:38:01] [valid] Ep. 1 : Up. 1070000 : perplexity : 4.25858 : stalled 6 times (last best: 4.25355)
[2022-03-09 16:10:53] Ep. 1 : Up. 1080000 : Sen. 45,732,248 : Cost 2.34456968 : Time 12786.34s : 16055.53 words/s : gNorm 0.6268
[2022-03-09 16:10:53] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 16:10:56] Saving Adam parameters
[2022-03-09 16:10:59] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 16:11:40] [valid] Ep. 1 : Up. 1080000 : perplexity : 4.25764 : stalled 7 times (last best: 4.25355)
[2022-03-09 19:44:35] Ep. 1 : Up. 1090000 : Sen. 54,887,710 : Cost 2.34401298 : Time 12821.59s : 16021.85 words/s : gNorm 0.6537
[2022-03-09 19:44:35] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 19:44:38] Saving Adam parameters
[2022-03-09 19:44:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 19:44:49] [valid] Ep. 1 : Up. 1090000 : perplexity : 4.25795 : stalled 8 times (last best: 4.25355)
[2022-03-09 23:17:56] Ep. 1 : Up. 1100000 : Sen. 64,018,771 : Cost 2.34286785 : Time 12801.55s : 16046.09 words/s : gNorm 0.6792
[2022-03-09 23:17:56] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-09 23:18:04] Saving Adam parameters
[2022-03-09 23:18:10] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-09 23:18:20] [valid] Ep. 1 : Up. 1100000 : perplexity : 4.25525 : stalled 9 times (last best: 4.25355)
[2022-03-10 02:51:18] Ep. 1 : Up. 1110000 : Sen. 73,175,796 : Cost 2.34322047 : Time 12802.12s : 16055.02 words/s : gNorm 0.6288
[2022-03-10 02:51:18] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 02:51:22] Saving Adam parameters
[2022-03-10 02:51:25] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 02:51:33] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-10 02:51:35] [valid] Ep. 1 : Up. 1110000 : perplexity : 4.25278 : new best
[2022-03-10 06:24:27] Ep. 1 : Up. 1120000 : Sen. 82,321,838 : Cost 2.34247541 : Time 12788.31s : 16061.91 words/s : gNorm 0.6406
[2022-03-10 06:24:27] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 06:24:30] Saving Adam parameters
[2022-03-10 06:24:33] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 06:24:41] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-10 06:24:43] [valid] Ep. 1 : Up. 1120000 : perplexity : 4.24824 : new best
[2022-03-10 09:57:38] Ep. 1 : Up. 1130000 : Sen. 91,465,281 : Cost 2.34274769 : Time 12791.48s : 16059.27 words/s : gNorm 0.7138
[2022-03-10 09:57:38] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 09:57:42] Saving Adam parameters
[2022-03-10 09:57:45] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 09:57:53] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-10 09:57:56] [valid] Ep. 1 : Up. 1130000 : perplexity : 4.24173 : new best
[2022-03-10 13:31:02] Ep. 1 : Up. 1140000 : Sen. 100,615,039 : Cost 2.34191871 : Time 12803.44s : 16051.85 words/s : gNorm 0.6532
[2022-03-10 13:31:02] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 13:31:05] Saving Adam parameters
[2022-03-10 13:31:08] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 13:31:17] [valid] Ep. 1 : Up. 1140000 : perplexity : 4.2424 : stalled 1 times (last best: 4.24173)
[2022-03-10 17:04:10] Ep. 1 : Up. 1150000 : Sen. 109,738,459 : Cost 2.34100461 : Time 12788.10s : 16067.26 words/s : gNorm 0.7248
[2022-03-10 17:04:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 17:04:13] Saving Adam parameters
[2022-03-10 17:04:17] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 17:04:26] [valid] Ep. 1 : Up. 1150000 : perplexity : 4.24348 : stalled 2 times (last best: 4.24173)
[2022-03-10 20:37:22] Ep. 1 : Up. 1160000 : Sen. 118,905,778 : Cost 2.34212255 : Time 12791.83s : 16055.08 words/s : gNorm 0.6665
[2022-03-10 20:37:22] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-10 20:37:25] Saving Adam parameters
[2022-03-10 20:37:28] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-10 20:37:36] [valid] Ep. 1 : Up. 1160000 : perplexity : 4.24386 : stalled 3 times (last best: 4.24173)
[2022-03-11 00:10:55] Ep. 1 : Up. 1170000 : Sen. 128,053,008 : Cost 2.34137535 : Time 12813.41s : 16036.94 words/s : gNorm 0.6776
[2022-03-11 00:10:55] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 00:10:59] Saving Adam parameters
[2022-03-11 00:11:02] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 00:11:11] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-11 00:11:14] [valid] Ep. 1 : Up. 1170000 : perplexity : 4.23925 : new best
[2022-03-11 03:44:04] Ep. 1 : Up. 1180000 : Sen. 137,193,522 : Cost 2.34062839 : Time 12788.62s : 16059.19 words/s : gNorm 0.6418
[2022-03-11 03:44:04] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 03:44:08] Saving Adam parameters
[2022-03-11 03:44:11] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 03:44:20] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-11 03:44:22] [valid] Ep. 1 : Up. 1180000 : perplexity : 4.23475 : new best
[2022-03-11 07:17:27] Ep. 1 : Up. 1190000 : Sen. 146,351,606 : Cost 2.34160995 : Time 12803.21s : 16043.05 words/s : gNorm 0.7364
[2022-03-11 07:17:27] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 07:17:30] Saving Adam parameters
[2022-03-11 07:17:34] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 07:17:42] [valid] Ep. 1 : Up. 1190000 : perplexity : 4.23641 : stalled 1 times (last best: 4.23475)
[2022-03-11 10:50:34] Ep. 1 : Up. 1200000 : Sen. 155,474,105 : Cost 2.34028077 : Time 12787.09s : 16055.73 words/s : gNorm 0.6668
[2022-03-11 10:50:34] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 10:50:38] Saving Adam parameters
[2022-03-11 10:50:41] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 10:50:49] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.best-perplexity.npz
[2022-03-11 10:50:51] [valid] Ep. 1 : Up. 1200000 : perplexity : 4.23419 : new best
[2022-03-11 14:24:02] Ep. 1 : Up. 1210000 : Sen. 164,619,953 : Cost 2.33945298 : Time 12807.94s : 16043.41 words/s : gNorm 0.6373
[2022-03-11 14:24:03] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 14:24:07] Saving Adam parameters
[2022-03-11 14:24:10] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 14:24:19] [valid] Ep. 1 : Up. 1210000 : perplexity : 4.23725 : stalled 1 times (last best: 4.23419)
[2022-03-11 17:57:20] Ep. 1 : Up. 1220000 : Sen. 173,759,503 : Cost 2.33964467 : Time 12797.61s : 16060.07 words/s : gNorm 0.6830
[2022-03-11 17:57:20] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 17:57:24] Saving Adam parameters
[2022-03-11 17:57:27] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 17:57:36] [valid] Ep. 1 : Up. 1220000 : perplexity : 4.23686 : stalled 2 times (last best: 4.23419)
[2022-03-11 21:30:32] Ep. 1 : Up. 1230000 : Sen. 182,912,066 : Cost 2.34046960 : Time 12791.84s : 16057.00 words/s : gNorm 0.6987
[2022-03-11 21:30:32] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-11 21:30:36] Saving Adam parameters
[2022-03-11 21:30:40] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-11 21:30:49] [valid] Ep. 1 : Up. 1230000 : perplexity : 4.23706 : stalled 3 times (last best: 4.23419)
[2022-03-12 15:47:10] [marian] Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-12 15:47:10] [marian] Running on r02g04.bullx as process 102527 with command line:
[2022-03-12 15:47:10] [marian] /projappl/project_2001194/marian-dev/build/marian --task transformer-big --optimizer-delay 2 --no-restore-corpus --early-stopping 10 --valid-freq 10000 --valid-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k --valid-metrics perplexity --valid-mini-batch 16 --valid-max-length 100 --valid-log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log --beam-size 6 --normalize 1 --allow-unk --workspace 15000 --model /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz --train-sets /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz --vocabs /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml --save-freq 10000 --disp-freq 10000 --log /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log --devices 0 1 --seed 1111 --tempdir /run/nvme/job_10919472/tmp --shuffle batches --sharding local --overwrite --keep-best
[2022-03-12 15:47:12] [config] after: 0e
[2022-03-12 15:47:12] [config] after-batches: 0
[2022-03-12 15:47:12] [config] after-epochs: 0
[2022-03-12 15:47:12] [config] all-caps-every: 0
[2022-03-12 15:47:12] [config] allow-unk: true
[2022-03-12 15:47:12] [config] authors: false
[2022-03-12 15:47:12] [config] beam-size: 6
[2022-03-12 15:47:12] [config] bert-class-symbol: "[CLS]"
[2022-03-12 15:47:12] [config] bert-mask-symbol: "[MASK]"
[2022-03-12 15:47:12] [config] bert-masking-fraction: 0.15
[2022-03-12 15:47:12] [config] bert-sep-symbol: "[SEP]"
[2022-03-12 15:47:12] [config] bert-train-type-embeddings: true
[2022-03-12 15:47:12] [config] bert-type-vocab-size: 2
[2022-03-12 15:47:12] [config] build-info: ""
[2022-03-12 15:47:12] [config] check-gradient-nan: false
[2022-03-12 15:47:12] [config] check-nan: false
[2022-03-12 15:47:12] [config] cite: false
[2022-03-12 15:47:12] [config] clip-norm: 0
[2022-03-12 15:47:12] [config] cost-scaling:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] cost-type: ce-mean-words
[2022-03-12 15:47:12] [config] cpu-threads: 0
[2022-03-12 15:47:12] [config] data-weighting: ""
[2022-03-12 15:47:12] [config] data-weighting-type: sentence
[2022-03-12 15:47:12] [config] dec-cell: gru
[2022-03-12 15:47:12] [config] dec-cell-base-depth: 2
[2022-03-12 15:47:12] [config] dec-cell-high-depth: 1
[2022-03-12 15:47:12] [config] dec-depth: 6
[2022-03-12 15:47:12] [config] devices:
[2022-03-12 15:47:12] [config]   - 0
[2022-03-12 15:47:12] [config]   - 1
[2022-03-12 15:47:12] [config] dim-emb: 1024
[2022-03-12 15:47:12] [config] dim-rnn: 1024
[2022-03-12 15:47:12] [config] dim-vocabs:
[2022-03-12 15:47:12] [config]   - 54728
[2022-03-12 15:47:12] [config]   - 54728
[2022-03-12 15:47:12] [config] disp-first: 0
[2022-03-12 15:47:12] [config] disp-freq: 10000
[2022-03-12 15:47:12] [config] disp-label-counts: true
[2022-03-12 15:47:12] [config] dropout-rnn: 0
[2022-03-12 15:47:12] [config] dropout-src: 0
[2022-03-12 15:47:12] [config] dropout-trg: 0
[2022-03-12 15:47:12] [config] dump-config: ""
[2022-03-12 15:47:12] [config] dynamic-gradient-scaling:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] early-stopping: 10
[2022-03-12 15:47:12] [config] early-stopping-on: first
[2022-03-12 15:47:12] [config] embedding-fix-src: false
[2022-03-12 15:47:12] [config] embedding-fix-trg: false
[2022-03-12 15:47:12] [config] embedding-normalization: false
[2022-03-12 15:47:12] [config] embedding-vectors:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] enc-cell: gru
[2022-03-12 15:47:12] [config] enc-cell-depth: 1
[2022-03-12 15:47:12] [config] enc-depth: 6
[2022-03-12 15:47:12] [config] enc-type: bidirectional
[2022-03-12 15:47:12] [config] english-title-case-every: 0
[2022-03-12 15:47:12] [config] exponential-smoothing: 0.0001
[2022-03-12 15:47:12] [config] factor-weight: 1
[2022-03-12 15:47:12] [config] factors-combine: sum
[2022-03-12 15:47:12] [config] factors-dim-emb: 0
[2022-03-12 15:47:12] [config] gradient-checkpointing: false
[2022-03-12 15:47:12] [config] gradient-norm-average-window: 100
[2022-03-12 15:47:12] [config] guided-alignment: none
[2022-03-12 15:47:12] [config] guided-alignment-cost: mse
[2022-03-12 15:47:12] [config] guided-alignment-weight: 0.1
[2022-03-12 15:47:12] [config] ignore-model-config: false
[2022-03-12 15:47:12] [config] input-types:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] interpolate-env-vars: false
[2022-03-12 15:47:12] [config] keep-best: true
[2022-03-12 15:47:12] [config] label-smoothing: 0.1
[2022-03-12 15:47:12] [config] layer-normalization: false
[2022-03-12 15:47:12] [config] learn-rate: 0.0002
[2022-03-12 15:47:12] [config] lemma-dependency: ""
[2022-03-12 15:47:12] [config] lemma-dim-emb: 0
[2022-03-12 15:47:12] [config] log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.train1.log
[2022-03-12 15:47:12] [config] log-level: info
[2022-03-12 15:47:12] [config] log-time-zone: ""
[2022-03-12 15:47:12] [config] logical-epoch:
[2022-03-12 15:47:12] [config]   - 1e
[2022-03-12 15:47:12] [config]   - 0
[2022-03-12 15:47:12] [config] lr-decay: 0
[2022-03-12 15:47:12] [config] lr-decay-freq: 50000
[2022-03-12 15:47:12] [config] lr-decay-inv-sqrt:
[2022-03-12 15:47:12] [config]   - 8000
[2022-03-12 15:47:12] [config] lr-decay-repeat-warmup: false
[2022-03-12 15:47:12] [config] lr-decay-reset-optimizer: false
[2022-03-12 15:47:12] [config] lr-decay-start:
[2022-03-12 15:47:12] [config]   - 10
[2022-03-12 15:47:12] [config]   - 1
[2022-03-12 15:47:12] [config] lr-decay-strategy: epoch+stalled
[2022-03-12 15:47:12] [config] lr-report: false
[2022-03-12 15:47:12] [config] lr-warmup: 8000
[2022-03-12 15:47:12] [config] lr-warmup-at-reload: false
[2022-03-12 15:47:12] [config] lr-warmup-cycle: false
[2022-03-12 15:47:12] [config] lr-warmup-start-rate: 0
[2022-03-12 15:47:12] [config] max-length: 100
[2022-03-12 15:47:12] [config] max-length-crop: false
[2022-03-12 15:47:12] [config] max-length-factor: 3
[2022-03-12 15:47:12] [config] maxi-batch: 1000
[2022-03-12 15:47:12] [config] maxi-batch-sort: trg
[2022-03-12 15:47:12] [config] mini-batch: 1000
[2022-03-12 15:47:12] [config] mini-batch-fit: true
[2022-03-12 15:47:12] [config] mini-batch-fit-step: 10
[2022-03-12 15:47:12] [config] mini-batch-round-up: true
[2022-03-12 15:47:12] [config] mini-batch-track-lr: false
[2022-03-12 15:47:12] [config] mini-batch-warmup: 0
[2022-03-12 15:47:12] [config] mini-batch-words: 0
[2022-03-12 15:47:12] [config] mini-batch-words-ref: 0
[2022-03-12 15:47:12] [config] model: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-12 15:47:12] [config] multi-loss-type: sum
[2022-03-12 15:47:12] [config] n-best: false
[2022-03-12 15:47:12] [config] no-nccl: false
[2022-03-12 15:47:12] [config] no-reload: false
[2022-03-12 15:47:12] [config] no-restore-corpus: true
[2022-03-12 15:47:12] [config] normalize: 1
[2022-03-12 15:47:12] [config] normalize-gradient: false
[2022-03-12 15:47:12] [config] num-devices: 0
[2022-03-12 15:47:12] [config] optimizer: adam
[2022-03-12 15:47:12] [config] optimizer-delay: 2
[2022-03-12 15:47:12] [config] optimizer-params:
[2022-03-12 15:47:12] [config]   - 0.9
[2022-03-12 15:47:12] [config]   - 0.998
[2022-03-12 15:47:12] [config]   - 1e-09
[2022-03-12 15:47:12] [config] output-omit-bias: false
[2022-03-12 15:47:12] [config] overwrite: true
[2022-03-12 15:47:12] [config] precision:
[2022-03-12 15:47:12] [config]   - float32
[2022-03-12 15:47:12] [config]   - float32
[2022-03-12 15:47:12] [config] pretrained-model: ""
[2022-03-12 15:47:12] [config] quantize-biases: false
[2022-03-12 15:47:12] [config] quantize-bits: 0
[2022-03-12 15:47:12] [config] quantize-log-based: false
[2022-03-12 15:47:12] [config] quantize-optimization-steps: 0
[2022-03-12 15:47:12] [config] quiet: false
[2022-03-12 15:47:12] [config] quiet-translation: false
[2022-03-12 15:47:12] [config] relative-paths: false
[2022-03-12 15:47:12] [config] right-left: false
[2022-03-12 15:47:12] [config] save-freq: 10000
[2022-03-12 15:47:12] [config] seed: 1111
[2022-03-12 15:47:12] [config] sentencepiece-alphas:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] sentencepiece-max-lines: 2000000
[2022-03-12 15:47:12] [config] sentencepiece-options: ""
[2022-03-12 15:47:12] [config] sharding: local
[2022-03-12 15:47:12] [config] shuffle: batches
[2022-03-12 15:47:12] [config] shuffle-in-ram: false
[2022-03-12 15:47:12] [config] sigterm: save-and-exit
[2022-03-12 15:47:12] [config] skip: false
[2022-03-12 15:47:12] [config] sqlite: ""
[2022-03-12 15:47:12] [config] sqlite-drop: false
[2022-03-12 15:47:12] [config] sync-freq: 200u
[2022-03-12 15:47:12] [config] sync-sgd: true
[2022-03-12 15:47:12] [config] tempdir: /run/nvme/job_10919472/tmp
[2022-03-12 15:47:12] [config] tied-embeddings: false
[2022-03-12 15:47:12] [config] tied-embeddings-all: true
[2022-03-12 15:47:12] [config] tied-embeddings-src: false
[2022-03-12 15:47:12] [config] train-embedder-rank:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] train-sets:
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.src.clean.spm32k.gz
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/train/opusTCv20210807+bt.trg.clean.spm32k.gz
[2022-03-12 15:47:12] [config] transformer-aan-activation: swish
[2022-03-12 15:47:12] [config] transformer-aan-depth: 2
[2022-03-12 15:47:12] [config] transformer-aan-nogate: false
[2022-03-12 15:47:12] [config] transformer-decoder-autoreg: self-attention
[2022-03-12 15:47:12] [config] transformer-depth-scaling: false
[2022-03-12 15:47:12] [config] transformer-dim-aan: 2048
[2022-03-12 15:47:12] [config] transformer-dim-ffn: 4096
[2022-03-12 15:47:12] [config] transformer-dropout: 0.1
[2022-03-12 15:47:12] [config] transformer-dropout-attention: 0
[2022-03-12 15:47:12] [config] transformer-dropout-ffn: 0
[2022-03-12 15:47:12] [config] transformer-ffn-activation: relu
[2022-03-12 15:47:12] [config] transformer-ffn-depth: 2
[2022-03-12 15:47:12] [config] transformer-guided-alignment-layer: last
[2022-03-12 15:47:12] [config] transformer-heads: 16
[2022-03-12 15:47:12] [config] transformer-no-projection: false
[2022-03-12 15:47:12] [config] transformer-pool: false
[2022-03-12 15:47:12] [config] transformer-postprocess: dan
[2022-03-12 15:47:12] [config] transformer-postprocess-emb: d
[2022-03-12 15:47:12] [config] transformer-postprocess-top: ""
[2022-03-12 15:47:12] [config] transformer-preprocess: ""
[2022-03-12 15:47:12] [config] transformer-tied-layers:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] transformer-train-position-embeddings: false
[2022-03-12 15:47:12] [config] tsv: false
[2022-03-12 15:47:12] [config] tsv-fields: 0
[2022-03-12 15:47:12] [config] type: transformer
[2022-03-12 15:47:12] [config] ulr: false
[2022-03-12 15:47:12] [config] ulr-dim-emb: 0
[2022-03-12 15:47:12] [config] ulr-dropout: 0
[2022-03-12 15:47:12] [config] ulr-keys-vectors: ""
[2022-03-12 15:47:12] [config] ulr-query-vectors: ""
[2022-03-12 15:47:12] [config] ulr-softmax-temperature: 1
[2022-03-12 15:47:12] [config] ulr-trainable-transformation: false
[2022-03-12 15:47:12] [config] unlikelihood-loss: false
[2022-03-12 15:47:12] [config] valid-freq: 10000
[2022-03-12 15:47:12] [config] valid-log: /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.valid1.log
[2022-03-12 15:47:12] [config] valid-max-length: 100
[2022-03-12 15:47:12] [config] valid-metrics:
[2022-03-12 15:47:12] [config]   - perplexity
[2022-03-12 15:47:12] [config] valid-mini-batch: 16
[2022-03-12 15:47:12] [config] valid-reset-stalled: false
[2022-03-12 15:47:12] [config] valid-script-args:
[2022-03-12 15:47:12] [config]   []
[2022-03-12 15:47:12] [config] valid-script-path: ""
[2022-03-12 15:47:12] [config] valid-sets:
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.src.spm32k
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/val/Tatoeba-dev-v2021-08-07.trg.spm32k
[2022-03-12 15:47:12] [config] valid-translation-output: ""
[2022-03-12 15:47:12] [config] version: v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-12 15:47:12] [config] vocabs:
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-12 15:47:12] [config]   - /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-12 15:47:12] [config] word-penalty: 0
[2022-03-12 15:47:12] [config] word-scores: false
[2022-03-12 15:47:12] [config] workspace: 15000
[2022-03-12 15:47:12] [config] Loaded model has been created with Marian v1.10.24; 12a1bfa 2021-10-11 16:59:52 +0100
[2022-03-12 15:47:12] Using synchronous SGD
[2022-03-12 15:47:12] [comm] Compiled without MPI support. Running as a single process on r02g04.bullx
[2022-03-12 15:47:12] Synced seed 1111
[2022-03-12 15:47:12] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-12 15:47:13] [data] Setting vocabulary size for input 0 to 54,728
[2022-03-12 15:47:13] [data] Loading vocabulary from JSON/Yaml file /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.vocab.yml
[2022-03-12 15:47:13] [data] Setting vocabulary size for input 1 to 54,728
[2022-03-12 15:47:13] [batching] Collecting statistics for batch fitting with step size 10
[2022-03-12 15:47:14] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-12 15:47:16] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-12 15:47:16] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-12 15:47:16] [comm] Using global sharding
[2022-03-12 15:47:17] [comm] NCCLCommunicators constructed successfully
[2022-03-12 15:47:17] [training] Using 2 GPUs
[2022-03-12 15:47:18] [logits] Applying loss function for 1 factor(s)
[2022-03-12 15:47:18] [memory] Reserving 886 MB, device gpu0
[2022-03-12 15:47:20] [gpu] 16-bit TensorCores enabled for float32 matrix operations
[2022-03-12 15:47:20] [memory] Reserving 886 MB, device gpu0
[2022-03-12 15:47:44] [batching] Done. Typical MB size is 27,536 target words
[2022-03-12 15:47:44] [memory] Extending reserved space to 15104 MB (device gpu0)
[2022-03-12 15:47:44] [memory] Extending reserved space to 15104 MB (device gpu1)
[2022-03-12 15:47:44] [comm] Using NCCL 2.8.3 for GPU communication
[2022-03-12 15:47:44] [comm] Using global sharding
[2022-03-12 15:47:44] [comm] NCCLCommunicators constructed successfully
[2022-03-12 15:47:44] [training] Using 2 GPUs
[2022-03-12 15:47:44] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-12 15:47:47] Loading model from /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-12 15:47:56] Allocating memory for general optimizer shards
[2022-03-12 15:47:56] [memory] Reserving 443 MB, device gpu0
[2022-03-12 15:47:56] [memory] Reserving 443 MB, device gpu1
[2022-03-12 15:47:56] Loading Adam parameters
[2022-03-12 15:47:57] [memory] Reserving 886 MB, device gpu0
[2022-03-12 15:47:57] [memory] Reserving 886 MB, device gpu1
[2022-03-12 15:47:57] [memory] Reserving 886 MB, device gpu0
[2022-03-12 15:47:58] [memory] Reserving 886 MB, device gpu1
[2022-03-12 15:47:58] [training] Master parameters and optimizers restored from training checkpoint /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-12 15:47:58] Training started
[2022-03-12 15:48:20] [training] Batches are processed as 1 process(es) x 2 devices/process
[2022-03-12 15:48:20] [memory] Reserving 886 MB, device gpu0
[2022-03-12 15:48:20] [memory] Reserving 886 MB, device gpu1
[2022-03-12 15:48:23] Parameter type float32, optimization type float32, casting types false
[2022-03-12 19:21:47] Ep. 1 : Up. 1240000 : Sen. 9,157,155 : Cost 2.33866930 : Time 12842.83s : 15992.22 words/s : gNorm 0.7361
[2022-03-12 19:21:47] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-12 19:21:51] Saving Adam parameters
[2022-03-12 19:21:54] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-12 19:22:02] [valid] Ep. 1 : Up. 1240000 : perplexity : 4.23751 : stalled 3 times (last best: 4.23419)
[2022-03-12 22:55:15] Ep. 1 : Up. 1250000 : Sen. 18,299,011 : Cost 2.33735156 : Time 12808.42s : 16049.93 words/s : gNorm 0.6711
[2022-03-12 22:55:15] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-12 22:55:21] Saving Adam parameters
[2022-03-12 22:55:24] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-12 22:55:33] [valid] Ep. 1 : Up. 1250000 : perplexity : 4.23865 : stalled 4 times (last best: 4.23419)
[2022-03-13 02:28:37] Ep. 1 : Up. 1260000 : Sen. 27,429,933 : Cost 2.33703637 : Time 12801.32s : 16047.39 words/s : gNorm 0.6165
[2022-03-13 02:28:37] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-13 02:28:41] Saving Adam parameters
[2022-03-13 02:28:44] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-13 02:28:52] [valid] Ep. 1 : Up. 1260000 : perplexity : 4.23883 : stalled 5 times (last best: 4.23419)
[2022-03-13 06:01:54] Ep. 1 : Up. 1270000 : Sen. 36,599,477 : Cost 2.33726859 : Time 12797.19s : 16057.91 words/s : gNorm 0.6610
[2022-03-13 06:01:54] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-13 06:01:58] Saving Adam parameters
[2022-03-13 06:02:01] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-13 06:02:13] [valid] Ep. 1 : Up. 1270000 : perplexity : 4.23753 : stalled 6 times (last best: 4.23419)
[2022-03-13 09:35:10] Ep. 1 : Up. 1280000 : Sen. 45,732,248 : Cost 2.33725071 : Time 12796.16s : 16043.22 words/s : gNorm 0.6472
[2022-03-13 09:35:10] Saving model weights and runtime parameters to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz
[2022-03-13 09:35:14] Saving Adam parameters
[2022-03-13 09:35:18] [training] Saving training checkpoint to /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz and /scratch/project_2001194/Opus-MT-train/tatoeba/work/cat+oci+spa-eng/opusTCv20210807+bt.spm32k-spm32k.transformer-big.model1.npz.optimizer.npz
[2022-03-13 09:35:26] [valid] Ep. 1 : Up. 1280000 : perplexity : 4.2367 : stalled 7 times (last best: 4.23419)
